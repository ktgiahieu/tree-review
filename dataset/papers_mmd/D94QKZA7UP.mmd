# A One-Size-Fits-All Approach to Improving

Randomness in Paper Assignment

 Yixuan Even Xu\({}^{1}\) Steven Jecmen\({}^{2}\) Zimeng Song\({}^{3}\) Fei Fang\({}^{2}\)

\({}^{1}\)Tsinghua University

\({}^{2}\)Carnegie Mellon University

\({}^{3}\)Independent Researcher

xuyx20@mails.tsinghua.edu.cn

{sjecmen,feif}@cs.cmu.edu

zmsongzm@gmail.com

This work was done when Xu was a visiting intern at Carnegie Mellon University.

###### Abstract

The assignment of papers to reviewers is a crucial part of the peer review processes of large publication venues, where organizers (e.g., conference program chairs) rely on algorithms to perform automated paper assignment. As such, a major challenge for the organizers of these processes is to specify paper assignment algorithms that find appropriate assignments with respect to various desiderata. Although the main objective when choosing a good paper assignment is to maximize the expertise of each reviewer for their assigned papers, several other considerations make introducing randomization into the paper assignment desirable: robustness to malicious behavior, the ability to evaluate alternative paper assignments, reviewer diversity, and reviewer anonymity. However, it is unclear in what way one should randomize the paper assignment in order to best satisfy all of these considerations simultaneously. In this work, we present a practical, one-size-fits-all method for randomized paper assignment intended to perform well across different motivations for randomness. We show theoretically and experimentally that our method outperforms currently-deployed methods for randomized paper assignment on several intuitive randomness metrics, demonstrating that the randomized assignments produced by our method are general-purpose.

## 1 Introduction

Peer review is the process in which submissions (such as scientific papers) are evaluated by expert reviewers. It is considered a critical part of the scientific process and is commonly used to determine which papers get published in journals and conferences. For concreteness, we set this work in the academic conference setting, although the approach can be generalized to other settings, such as peer review for grant proposals and peer grading in classrooms. Due to the large scale of modern conferences like NeurIPS and AAAI, conference program chairs work closely with assignment algorithms to assign papers to reviewers automatically. Among many other challenges involved in managing huge numbers of reviewers and submissions, these organizers are faced with the difficult task of balancing various considerations for the paper assignment. Human-friendly automated paper assignment algorithms are thus crucial for helping them find desirable paper assignments.

In a standard paper assignment setting, a set \(\mathcal{P}\) of \(n_{p}\) papers need to be assigned to a set \(\mathcal{R}\) of \(n_{r}\) reviewers. To ensure each paper gets enough reviewers and no reviewer is overloaded with papers, each paper \(p\) in \(\mathcal{P}\) should be assigned to \(\ell_{p}\) reviewers and each reviewer \(r\) in \(\mathcal{R}\) should receive no more than \(\ell_{r}\) papers. An assignment is represented as a binary matrix \(\mathbf{x}\) in \(\{0,1\}^{n_{p}\times n_{r}}\), where \(x_{p,r}=1\) indicates that paper \(p\) is assigned to reviewer \(r\). The main objective of paper assignment is usually to maximize the predicted match quality between reviewers and papers [1]. To characterize this,a similarity matrix \(\mathbf{S}\) in \(\mathbb{R}_{\geq 0}^{n_{p}\times n_{r}}\) is commonly assumed [1, 2, 3, 4, 5, 6, 7]. Here, \(S_{p,r}\) represents the predicted quality of review from reviewer \(r\) for paper \(p\) and is generally computed from various sources [8]: reviewer and paper subject areas, reviewer-selected bids, and textual similarity between the paper and the reviewer's past work [1, 9, 10, 11, 12]. Then, the **quality** of an assignment can be defined as the total similarity of all assigned paper reviewer pairs, i.e., \(\mathrm{Quality}(\mathbf{x})=\sum_{p,r}x_{p,r}S_{p,r}\). One standard approach for computing a paper assignment is to maximize quality [1, 4, 5, 6, 7, 13] (which we will refer to as the maximum-quality assignment). Variants of this approach have been widely used by existing conferences, such as NeurIPS, AAAI, and ICML [8].

While the deterministic maximum-quality assignment is the most common, there are strong reasons to introduce randomness into paper assignment - that is, to determine a probability distribution over feasible deterministic assignments and sample one assignment from the distribution. Specifically, randomized paper assignments are beneficial due to the following motivations:

* **Motivation 1: Robustness to malicious behavior.** Several computer science conferences have uncovered "collusion rings" of reviewers and authors [14, 15], in which the reviewers aim to get assigned to the authors' papers in order to give them good reviews without considering their merits. By manipulating their stated expertise and interest (e.g., in the "paper bidding" process), these reviewers can cause the assignment algorithm to believe that their match quality with the targeted papers is very high. In other cases, reviewers may target assignment to a paper with the aim of giving it an unfair negative review [16, 17, 18]. Randomization can reduce the probability that a malicious reviewer achieves assignment to a target paper.
* **Motivation 2: Evaluation of alternative assignments.** Accurate reviewer-paper similarity scores are fundamental for automated paper assignment algorithms. Despite this, these scores are currently computed using various different methods by different conferences [19, 20], with no obvious way to tell beforehand which method produces the best-quality reviews. However, after deploying an assignment, it is possible to examine the resulting reviews to counterfactually evaluate the review quality produced by another method of similarity computation that is not deployed. Specifically, using techniques for off-policy evaluation [21], the randomness of the deployed paper assignment can be utilized to estimate the review quality of another non-deployed assignment. The variance of the estimation depends on the overlap in assignment probability between the deployed (randomized) assignment and the non-deployed alternative assignments of interest. Such an evaluation can then inform program chairs on how similarities should be computed (or how other algorithmic choices should be made) in the future.
* **Motivation 3: Reviewer diversity.** As each paper is evaluated by multiple reviewers, it is often desirable to assign a set of reviewers with diverse perspectives or areas of expertise. However, since maximum-quality assignments compute only a holistic score to represent the expertise of each reviewer-paper pair, they do not consider this factor. Randomization can increase diversity by spreading out assignment probability among a larger set of high-expertise reviewers.
* **Motivation 4: Reviewer anonymity.** In peer review, reviewer identities are hidden from authors so that authors cannot retaliate for negative reviews. As a result, conferences are generally reluctant to release paper assignment data since authors may be able to deduce the identities of their reviewers (even if reviewer names and other information are hidden). By sufficiently randomizing the assignment, conferences can make it difficult for authors to identify any reviewer on their paper with high probability from the assignment data.

Despite the significance of randomness in paper assignment, there is very limited prior work that looks into computing randomized assignments. A notable exception is [22], which proposed an algorithm for computing randomized paper assignments: **Probability Limited Randomized Assignment (PLRA)**. Formally, it represents a randomized assignment as a matrix \(\mathbf{x}\) in \([0,1]^{n_{p}\times n_{r}}\), where \(x_{p,r}\) denotes the marginal probability that paper \(p\) is assigned to reviewer \(r\). PLRA computes a randomized assignment via the following linear program (LP), defined for a given parameter \(Q\in[0,1]\) as:

\[\begin{array}{ll}\text{Maximize}&\mathrm{Quality}(\mathbf{x})=\sum_{p,r}x _{p,r}S_{p,r}\\ \text{Subject to}&\sum_{r}x_{p,r}=\ell_{p}&\forall p\in\mathcal{P},\\ &\sum_{p}x_{p,r}\leq\ell_{r}&\forall r\in\mathcal{R},\\ &0\leq x_{p,r}\leq Q&\forall p\in\mathcal{P},r\in\mathcal{R},\end{array}\] (PLRA)where \(\mathrm{Quality}(\mathbf{x})\) for a randomized assignment \(\mathbf{x}\) is the expected total similarity of the assignment. A deterministic assignment can then be sampled, using the fact that any feasible randomized assignment \(\mathbf{x}\) can be implemented as a distribution over feasible deterministic assignments [22; 23].

PLRA is primarily concerned with the first motivation for randomization: robustness to malicious behavior. By limiting each entry of \(\mathbf{x}\) to be at most \(Q\), PLRA guarantees that any malicious reviewer aiming to be assigned to a target paper has at most probability \(Q\) to succeed, even if the reviewer and paper are chosen adversarially. The hyperparameter \(Q\) can be adjusted to balance the loss in quality and level of randomization. PLRA has been deployed in multiple iterations of the AAAI conference [8] and is implemented at the popular conference management system OpenReview.net [24].

However, PLRA does not fully solve the problem of randomized paper assignment. In particular, PLRA is specific to one metric of randomness: the maximum assignment probability across all peer-reviewer pairs. As a result, it is not clear how well PLRA aligns with motivations for randomization other than robustness to malicious behavior. Moreover, PLRA does not distinguish between different solutions with the same quality and maximum assignment probability. This means that it often loses opportunities to add additional randomness since it neglects to consider non-maximum assignment probabilities. One way to remedy this issue is to allow different values of \(Q\) to be set for each pair \((p,r)\), as in the original formulation of [22]. However, this level of flexibility makes it a significant burden for program chairs to manually choose appropriate \(Q\) values, hindering the usability of the algorithm. As a result, only the single-\(Q\) version stated above has been deployed in practice.

In this work, we address the problem of randomizing paper assignment by looking for a simple and practical method of achieving general-purpose randomized paper assignments. We consider various intuitive randomness metrics that are relevant to all above motivations but not overly specific to a particular problem formulation, and aim to provide a method that performs well across these metrics. In this way, we can provide a method for randomized paper assignment that conference program chairs can easily deploy without needing to precisely specify objectives or hyperparameters.

More specifically, we make the following contributions in this work. **(1).** We define several metrics to measure the extent to which the randomization in a randomized paper assignment satisfies the stated motivations (Section 3). **(2).** We propose Perturbed Maximization (PM), a practical algorithm for randomized paper assignment that does not rely on any specific formulation of the stated motivations (Section 4). While our algorithm can be implemented using a standard convex optimization solver, we additionally propose an approximate implementation that is computationally cheaper. **(3).** We provide theoretical results showing that PM provably outperforms PLRA on two classes of structured similarity scores (Section 5). **(4).** We extensively evaluate our algorithm via experiments using two realistic datasets of similarity scores from AAMAS 2015 and ICLR 2018 (Section 6). PM simultaneously performs well on all defined randomness metrics while sacrificing a small amount of quality as compared to the optimal non-randomized assignment. Additionally, our experiments show that PM achieves good performance when hyperparameters are set based only on the desired assignment quality, ensuring that it is simple for program chairs to deploy in practice.

## 2 Related Work

This work follows a recent area of research in computer science on paper assignment algorithms for peer review. Building on the standard approach of maximum-similarity assignment, algorithms have been proposed to handle various additional considerations in the paper assignment: the fairness across papers [2], the seniority of reviewers [20], review processes with multiple phases [3], strategyproofness [25; 26], and many others [8]. We note here specifically two relevant lines of work.

One motivation for our randomized assignment algorithm is to provide robustness to malicious reviewers, a problem considered by several past works [27; 28]. Although our work most closely relates to the randomized paper assignment algorithm proposed in [22], other non-randomized approaches to the problem exist. Leyton-Brown et al. [20] describe the paper assignment process used at AAAI 2021, which included several additional soft constraints intended to curb the possibility of reviewer-author collusion rings. Wu et al. [29] propose fitting a model of reviewer bidding in order to smooth out irregular bids. Boehmer et al. [30] consider computing paper assignments without short-length cycles in order to prevent quid-pro-quo agreements between reviewers.

Randomization in the paper assignment process has also been used for evaluating different assignment policies. Traditionally, conferences will sometimes run randomized controlled experiments in order to test policy changes, where the randomization is incorporated in the assignment of reviewers to different experimental conditions. For example, WSDM 2017 randomly separated reviewers into single- and double-blind conditions in order to evaluate the benefits of double-blind reviewing [31]; other notable experiments include NeurIPS 2014 [32, 33], ICML 2020 [34], and NeurIPS 2021 [35]. In contrast, recent work by Saveski et al. [21] proposes a method for evaluating alternative assignment policies by leveraging randomization in the paper assignment itself, such as the randomized paper assignments of [22]. By introducing additional randomness at a low cost, our algorithm provides an improved basis for the methods of [21] and potential future counterfactual policy evaluation methods.

## 3 Metrics for Randomness and Problem Statement

In Section 1, we introduced several motivations for choosing randomized paper assignments: robustness to malicious behavior, evaluation of alternative assignments, reviewer diversity, and reviewer anonymity. These indicate that assignment quality is not the only objective that should be considered when choosing a paper assignment. In this section, we propose several metrics to characterize the extent to which the randomness in a paper assignment is practically useful.

One randomness metric considered by PLRA is **maximum probability**, defined as \(\mathrm{Maxprob}(\mathbf{x})=\max_{p,r}\{x_{p,r}\}\). PLRA controls \(\mathrm{Maxprob}\) in order to trade off between quality and randomness, and thus achieves the greatest possible quality for a fixed level of \(\mathrm{Maxprob}\). However, as the following example shows, this metric alone is not sufficient to fully characterize the randomness of a paper assignment since it ignores the structure of the assignment with non-maximum probability.

Fig. 1 depicts a mini-conference consisting of 2 subject areas. Subject area A contains 3 papers and 3 reviewers, whereas subject area B contains 2 of each. The similarities between reviewers and papers within the same subject area are 1 and similarities across subject areas are 0. The constraints are \(\ell_{p}=\ell_{r}=1\), i.e., one-to-one assignment. Intuitively, the best randomized assignment matches papers and reviewers uniformly at random within each subject area, like Fig. 0(a), since this does not sacrifice any quality. However, PLRA fails to give out this ideal assignment regardless of the hyperparameter choice. Specifically, \(Q\geq 1/2\) is required for PLRA to get a maximum-quality assignment, but when \(Q\geq 1/2\), PLRA considers Fig. 0(a) and Fig. 0(b) to be equivalent (in terms of objective value). In fact, infinitely many solutions with the same optimal quality are considered equivalent by PLRA, and current LP solvers tend to return Fig. 0(b) as it is a vertex solution when \(Q=1/2\). In essence, PLRA is leaving "free randomness on the table," with many practical implications.

Consider the problem of mitigating malicious behavior (Motivation 1), and compare the assignments in Figs. 0(a) and 0(b). Although they appear to have the same \(\mathrm{Maxprob}\), when we only look at subject area A, the \(\mathrm{Maxprob}\) of Fig. 0(a) is lower than that of Fig. 0(b). This indicates that Fig. 0(a) is more robust to malicious behavior within subject area A. Therefore, Fig. 0(a) is more desirable.

Moreover, as introduced in Motivation 2, randomness can also be leveraged to evaluate alternative paper assignments using observations of the review quality from a deployed, randomized assignment. These techniques rely on a "positivity" assumption: paper-reviewer pairs assigned in the alternative assignment must be given non-zero probability in the deployed assignment. Thus, if we spread assignment probability more uniformly among more reviewer-paper pairs, the resulting data can be

Figure 1: Example showing the limitations of PLRA. There are 2 subject areas with 5 papers and 5 reviewers. \(\ell_{p}=\ell_{r}=1\). The similarity of paper-reviewer pair is 1 if they are in the same area. The edge weights denote the assignment probability. (a) shows the ideal assignment with optimal quality. (b) shows an assignment by PLRA with \(Q=\frac{1}{2}\), which is less randomized than (a) in subject area A.

used to evaluate more varied strategies with tighter bounds. In this sense, the assignment in Fig. 0(a) will allow us to better estimate the quality of different paper assignments within subject area A.

The failure of PLRA on such a simple example shows that \(\mathrm{Maxprob}\) alone is an inadequate metric. Thus, we need other metrics to distinguish between assignments like Fig. 0(a) and Fig. 0(b). We therefore propose, in addition to \(\mathrm{Maxprob}\), a set of new randomness metrics to capture the neglected low-probability structure of an assignment. Under each of these metrics, a uniform assignment is considered "more random" than any other assignment, thus distinguishing Fig. 0(a) from Fig. 0(b).

1. **Average maximum probability:**\(\mathrm{AvgMaxp}(\mathbf{x})=\frac{1}{n_{p}}\sum_{p}\max_{r}\{x_{p,r}\}\). With respect to the motivation of preventing malicious behavior, this randomness metric corresponds to the case when a target paper is randomly chosen and the reviewer targeting assignment to that paper is adversarially chosen. By minimizing average maximum probability, we will limit the success probability of manipulation in that case.
2. **Support size:**\(\mathrm{Support}(\mathbf{x})=\sum_{p,r}\mathbb{I}[x_{p,r}>0]\). Support size directly relates to the "positivity" assumption introduced above. As there may be many alternative paper assignments of interest, maximizing the support size effectively maximizes the quality of estimation across them.
3. **Entropy:**\(\mathrm{Entropy}(\mathbf{x})=-\sum_{p,r}x_{p,r}\ln(x_{p,r})\). In information theory, entropy characterizes the uncertainty of a random variable. By maximizing entropy, we maximize the uncertainty of our assignment, corresponding to the idea of maximizing randomness. Note that strictly speaking, assignment \(\mathbf{x}\) is not a probability distribution, so this definition is a generalization.
4. **L2 norm:**\(\mathrm{L2Norm}(\mathbf{x})=\sqrt{\sum_{p,r}x_{p,r}^{2}}\). To prevent manipulation, PLRA limits the assigned probability of each pair to be at most a specified value \(Q\). L2 norm relaxes this constraint to a soft one: a higher probability results in a larger loss. Note that a uniformly random assignment will always have the smallest L2 norm, and so minimizing L2 norm pushes the assignment towards the uniform assignment.

The combination of these metrics more comprehensively captures the impact of randomness on the motivations from Section 1. Moreover, they do so without requiring a specific problem formulation for each motivation (e.g., an assumption on the behavior of malicious reviewers, a list of the alternative assignments of interest), which are impractical or infeasible to accurately specify in practice.

**Problem statement.** For an input instance \((n_{p},n_{r},\ell_{p},\ell_{r},\mathbf{S})\), we want to find an algorithm achieving a good trade-off between quality and randomness. Specifically, let the maximum possible quality be \(M\). For a given lower bound of assignment quality \(\eta M\) (\(\eta\in[0,1]\)), we want the algorithm to produce an assignment \(\mathbf{x}\) with lower \(\mathrm{Maxprob}(\mathbf{x}),\mathrm{AvgMaxp}(\mathbf{x}),\mathrm{L2Norm}( \mathbf{x})\) and higher \(\mathrm{Entropy}(\mathbf{x}),\mathrm{Support}(\mathbf{x})\), i.e., a good Pareto-frontier of quality and randomness.

## 4 Perturbed Maximization

In this section, we present our proposed algorithm for randomized paper assignment. To describe it, we first present some definitions.

**Definition 4.1** (Perturbation Function).: _A function \(f:[0,1]\rightarrow[0,1]\) is a **perturbation function** if (i) \(f(0)=0\), (ii) \(f^{\prime}\) exists, (iii) \(f\) is non-decreasing on \([0,1]\) and (iv) \(f\) is concave on \([0,1]\)._

**Definition 4.2** (Perturbed Quality).: _For an assignment \(\mathbf{x}\), its **perturbed quality** with respect to perturbation function \(f\) on instance \((n_{p},n_{r},\ell_{p},\ell_{r},\mathbf{S})\) is \(\mathrm{PQuality}_{f}(\mathbf{x})=\sum_{p,r}S_{p,r}\cdot f(x_{p,r})\)._

The definition of perturbed quality incorporates the intuition from the motivating example in the previous section. As function \(f\) is concave, the marginal increase of \(\mathrm{PQuality}_{f}(\mathbf{x})\) from increasing a specific entry \(x_{p,r}\) is diminishing as \(x_{p,r}\) grows. Consequently, the assignment of Fig. 0(a) will have a higher perturbed quality than that of Fig. 0(b). This naturally gives our new algorithm, **Perturbed Maximization (PM)**. For a given parameter \(Q\in[0,1]\) and a perturbation function \(f\):

\[\begin{array}{ll}\mathrm{Maximize}&\mathrm{PQuality}_{f}(\mathbf{x})=\sum_{ p,r}S_{p,r}\cdot f(x_{p,r})\\ \mathrm{Subject\ to}&\sum_{r}x_{p,r}=\ell_{p}\\ &\sum_{p}x_{p,r}\leq\ell_{r}\\ &0\leq x_{p,r}\leq Q\end{array}\qquad\qquad\qquad\qquad\forall p\in\mathcal{ P},\\ \forall r\in\mathcal{R},\\ &\forall p\in\mathcal{P},r\in\mathcal{R}.\end{array}\] (PM)Note that PM is a class of algorithms induced by different perturbation functions. When the perturbation function \(f\) is chosen to be a linear function, PM becomes PLRA. In the main experiments of this paper, two specific perturbation functions are considered: **(1). Exponential Perturbation Function:**\(f(x)=1-e^{-\alpha x}\) where \(\alpha\in(0,+\infty)\) and **(2). Quadratic Perturbation Function:**\(f(x)=x-\beta x^{2}\) where \(\beta\in[0,1]\). Respectively, we will denote PM with \(f(x)=1-e^{-\alpha x}\) and \(f(x)=x-\beta x^{2}\) as **PM-Exponential (PM-E)** and **PM-Quadratic (PM-Q)** in the rest of the paper.

In Section 6, we will empirically show that under our settings of hyperparameters, PM-E and PM-Q have almost identical performances on every metric we consider, which suggests that the specific form of the perturbation function has limited impact as long as it is strictly concave. Therefore, there is likely no need to consider many different types of perturbation functions.

To analyze PM, first notice that the concaveness of function \(f\) guarantees that the optimization program is concave. Therefore, we can use standard concave optimization methods like gradient ascent or the ellipsoid method to solve the program in polynomial time. In most of the experiments of this paper, we will use Gurobi [36], a well-known commercial solver, to solve PM. While solving PM as a general concave optimization problem is conceptually convenient, doing so also incurs a high time complexity as there are \(n_{p}\cdot n_{r}\) variables. To further speed up the execution of PM, we propose Algorithm 1, a network-flow-based approximation of PM.

**Algorithm 1**: Network-Flow-Based Approximation of PM

For a given parameter \(Q\in[0,1]\), a perturbation function \(f\) and a precision \(w\in\mathbb{N}^{+}\):

Construct a graph \(G\) with a source \(s\), a sink \(t\).

Construct \(p\), add a vertex \(v_{p}\) and an edge \(s\to v_{p}\) with capacity \(\ell_{p}\cdot w\) and cost \(0\).

For reviewer \(r\), add a vertex \(v_{r}\) and an edge \(v_{r}\to t\) with capacity \(\ell_{r}\cdot w\) and cost \(0\).

For a reviewer-paper pair \((p,r)\), add \(|Q\cdot w|\) edges \(v_{p}\to v_{r}\). The \(i\)-th edge has capacity \(1\) and cost \(S_{p,r}\cdot[f(\frac{i}{w})-f(\frac{i-1}{w})]\). Let this set of edges be \(E_{p,r}\).

Run maximum cost maximum flow algorithm [37] on \(G\). Define the assignment \(\mathbf{x}\) such that \(x_{p,r}=[\)The total flow on edges in \(E_{p,r}]/w\).

Enumerate all pairs \((p,r)\) in any order and increase \(x_{p,r}\) by \(\min\{Q-x_{p,r},\ell_{p}-\sum_{r}x_{p,r},\ell_{r}-\sum_{p}x_{p,r}\}\). If \(\sum_{p,r}x_{p,r}=n_{p}\cdot\ell_{p}\), return \(\mathbf{x}\). Otherwise, return infeasible.

At a high level, Algorithm 1 uses a piecewise linear function with \(w\) pieces to approximate the concave function \(f(x)\) and solves the approximated objective with maximum cost maximum flow. As we increase the precision \(w\), the approximation becomes more accurate, but the running time of the algorithm also scales up. Formally, we have the following Theorem 1.

**Theorem 1**.: _Let \(w\in\mathbb{N}^{+}\) be the precision in Algorithm 1, and \(\mathrm{OPT}\) be the optimal perturbed quality._

1. _Algorithm 1 runs in_ \(O(w\cdot\ell_{p}\cdot{n_{p}}^{2}\cdot n_{r})\) _time._
2. _Algorithm 1 returns an assignment with perturbed quality_ \(\mathrm{ALG}\geq\mathrm{OPT}-f(\frac{1}{w})\sum_{p,r}S_{p,r}\)_._

The proof of Theorem 1 is deferred to Appendix B.1.

Consider the running time of Algorithm 1 given in Theorem 1 (a). If we directly model PM as an optimization problem, the number of variables will be \(n=n_{p}\cdot n_{r}\). The state-of-the-art algorithm for solving a linear program with \(n\) variables to high accuracy has a time complexity of \(O^{*}(n^{2.38}\log n)\)[38]. In contrast, for fixed \(w\), Algorithm 1 works in \(O(n^{2})\) time since \(\ell_{p}\leq n_{r}\). Thus, Algorithm 1 has a better time complexity than directly solving PM as an optimization program even if the objective is linear. For non-linear perturbation functions, the time complexity of Algorithm 1 remains the same while the complexity of solving the optimization program increases. Moreover, by Theorem 1 (b), we can see that as \(w\) increases, the approximated perturbed quality \(\mathrm{ALG}\) approaches \(\mathrm{OPT}\), formalizing the intuition that as we increase the precision \(w\), the approximation becomes more accurate. In Section 6, we empirically evaluate the running time and the approximation accuracy of Algorithm 1. We find with \(w=10\), Algorithm 1 produces decently-accurate approximations on our datasets.

Theoretical Analysis

In this section, we provide two theorems showing that PM provably outperforms PLRA on a general class of input instances. We start with the simpler one inspired by the example in Fig. 1. Let \(\mathrm{PLRA}(Q)\) and \(\mathrm{PM}(Q,f)\) be the set of possible solutions of PLRA and PM respectively.

**Definition 5.1** (Blockwise Dominant Matrix).: _A similarity matrix \(\mathbf{S}\in\mathbb{R}_{\geq 0}^{n_{p}\times n_{r}}\) is **blockwise dominant** with **block identity \(\mathbf{A}\in\mathbb{R}_{\geq 0}^{k\times k}\) and **block sizes \(\{p_{1},\ldots,p_{k}\},\{r_{1},\ldots,r_{k}\}\)** if_

\[\mathbf{S}=\begin{pmatrix}A_{1,1}\cdot\mathbf{1}_{p_{1}\times r_{1}}&A_{1,2} \cdot\mathbf{1}_{p_{1}\times r_{2}}&\ldots&A_{1,k}\cdot\mathbf{1}_{p_{1}\times r _{k}}\\ A_{2,1}\cdot\mathbf{1}_{p_{2}\times r_{1}}&A_{2,2}\cdot\mathbf{1}_{p_{2}\times r _{2}}&\ldots&A_{2,k}\cdot\mathbf{1}_{p_{2}\times r_{k}}\\ \ldots&\ldots&\ldots&\ldots\\ A_{k,1}\cdot\mathbf{1}_{p_{k}\times r_{1}}&A_{k,2}\cdot\mathbf{1}_{p_{k}\times r _{2}}&\ldots&A_{k,k}\cdot\mathbf{1}_{p_{k}\times r_{k}}\end{pmatrix},\]

_where \(A_{i,i}>A_{i,j},\forall i\neq j\) and \(\mathbf{1}_{p\times r}\) is a \(p\times r\) matrix with all entries being \(1\). Moreover, define the **dominance factor** of \(\mathbf{A}\) as \(\mathrm{Dom}(\mathbf{A})=\sup\{\alpha\mid A_{i,i}\geq\alpha\cdot A_{i,j}, \forall i\neq j\}\)._

**Remark.** Like Fig. 1, a blockwise dominant similarity matrix models a conference with \(k\) subject areas where the \(i\)-th subject area has \(p_{i}\) papers and \(r_{i}\) reviewers. The similarity between a paper and a reviewer is determined only by their subject areas, and a paper has highest similarity with a reviewer in the same subject area. Note that \(\mathrm{Dom}(\mathbf{A})>1\) as \(A_{i,i}>A_{i,j},\forall i\neq j\).

**Theorem 2**.: _For an input instance \((n_{p},n_{r},\ell_{p},\ell_{r},\mathbf{S})\), where \(\mathbf{S}\) is blockwise dominant with block identity \(\mathbf{A}\in\mathbb{R}_{\geq 0}^{k\times k}\) and block sizes \(\{p_{1},\ldots,p_{k}\},\{r_{1},\ldots,r_{k}\}\), assume (i) \(\{r_{1},\ldots,r_{k}\}\) are not all equal, (ii) \(p_{i}\cdot\ell_{p}\leq r_{i}\cdot\ell_{r}\)\(\forall i\in\{1,\ldots,k\}\) and (iii) \(Q\cdot r_{i}\geq\ell_{p}\)\(\forall i\in\{1,\ldots,k\}\). Let \(f\) be a strictly concave perturbation function and \(f^{\prime}(0)<\mathrm{Dom}(\mathbf{A})f^{\prime}(1)\). PM with \(f(x)\) as the perturbation function (weakly) dominates PLRA in quality and all randomness metrics. Formally,_

* \(\forall\mathbf{x}\in\mathrm{PM}(Q,f)\)_,_ \(\forall\mathbf{y}\in\mathrm{PLRA}(Q)\)_,_ \[\mathrm{Quality}(\mathbf{x})\geq\mathrm{Quality}(\mathbf{y}), \quad\mathrm{Maxprob}(\mathbf{x})\leq\mathrm{Maxprob}(\mathbf{y}),\quad \mathrm{AvgMaxp}(\mathbf{x})\leq\mathrm{AvgMaxp}(\mathbf{y}),\] \(\mathrm{L2Norm}(\mathbf{x})\leq\mathrm{L2Norm}(\mathbf{y}),\quad \mathrm{Entropy}(\mathbf{x})\geq\mathrm{Entropy}(\mathbf{y}),\quad\mathrm{ Support}(\mathbf{x})\geq\mathrm{Support}(\mathbf{y}).\]
* \(\forall\mathbf{x}\in\mathrm{PM}(Q,f)\)_,_ \(\exists\mathbf{y}\in\mathrm{PLRA}(Q)\)_,_ \[\mathrm{AvgMaxxp}(\mathbf{x})<\mathrm{AvgMaxxp}(\mathbf{y}),\quad\mathrm{L2 Norm}(\mathbf{x})<\mathrm{L2Norm}(\mathbf{y}),\quad\mathrm{Entropy}(\mathbf{x})> \mathrm{Entropy}(\mathbf{y}).\]

The proof of Theorem 2 follows the same intuition as the example in Fig. 1. The assumptions guarantee that an assignment like Fig. 1a, i.e., uniformly matching papers to reviewers within the same subject area, is feasible. Details of the proof are deferred to Appendix B.2. At a high level, Theorem 2 shows that with a slight restriction on the perturbation function, PM provably performs better than PLRA on blockwise dominant similarity matrices.

Theorem 2 requires a strict restriction on \(\mathbf{S}\)'s structure. In our next theorem, we remove the restriction, stating that PM also outperforms PLRA on a random similarity matrix with high probability.

**Theorem 3**.: _For an input instance \((n_{p},n_{r},\ell_{p},\ell_{r},\mathbf{S})\), where each entry of \(\mathbf{S}\) is i.i.d. sampled from \(\{v_{1},\ldots,v_{k}\}\)\((0<v_{1}<\cdots<v_{k})\) uniformly, assume (i) \(k\leq\frac{1}{c}\cdot n_{p}\), (ii) \(\ell_{r}\geq c\cdot\ln(n_{r})\), (iii) \(2\cdot n_{p}\cdot\ell_{p}\leq n_{r}\cdot\ell_{r}\) and (iv) \(Q\cdot(n_{r}-1)\geq\ell_{p}\). Let \(f\) be a strictly concave perturbation function and \(f^{\prime}(0)<\frac{v_{1}}{v_{i-1}}f^{\prime}(1),\forall i\in\{2,\ldots,k\}\). With probability \(1-e^{-\Omega(c)}\), PM with \(f(x)\) as the perturbation function (weakly) dominates PLRA in quality and all randomness metrics. Formally,_

* \(\forall\mathbf{x}\in\mathrm{PM}(Q,f)\)_,_ \(\forall\mathbf{y}\in\mathrm{PLRA}(Q)\)_,_ \[\mathrm{Quality}(\mathbf{x})\geq\mathrm{Quality}(\mathbf{y}), \quad\mathrm{Maxprob}(\mathbf{x})\leq\mathrm{Maxprob}(\mathbf{y}),\quad \mathrm{AvgMaxp}(\mathbf{x})\leq\mathrm{AvgMaxp}(\mathbf{y}),\] \(\mathrm{L2Norm}(\mathbf{x})\leq\mathrm{L2Norm}(\mathbf{y}),\quad \mathrm{Entropy}(\mathbf{x})\geq\mathrm{Entropy}(\mathbf{y}),\quad\mathrm{ Support}(\mathbf{x})\geq\mathrm{Support}(\mathbf{y}).\]
* \(\forall\mathbf{x}\in\mathrm{PM}(Q,f)\)_,_ \(\exists\mathbf{y}\in\mathrm{PLRA}(Q)\)_,_ \[\mathrm{Support}(\mathbf{x})>\mathrm{Support}(\mathbf{y}),\quad\mathrm{L2Norm}( \mathbf{x})<\mathrm{L2Norm}(\mathbf{y}),\quad\mathrm{Entropy}(\mathbf{x})> \mathrm{Entropy}(\mathbf{y}).\]

The complete proof of Theorem 3 is deferred to Appendix B.3. To sketch the proof, we will first relate PLRA and PM to two simpler auxiliary algorithms using a concentration inequality and then prove the dominance between them. The assumptions (ii) and (iii) are used to connect PM and PLRA with the auxiliary algorithms, while (i) and (iv) are for proving the dominance.

For Theorem 3 to hold on general random similarity matrices, we have made a major assumption (i), which requires that there are not too many distinct levels of similarity scores. Assumption (i) is naturally satisfied in some cases. For example, when the similarities are derived purely from reviewers' bids, the number of levels becomes the number of discrete bid levels; discrete values can also result when computing similarities from the overlap between reviewer- and author-selected subject areas. When the similarity scores are instead computed from continuous values like TPMS scores [1], assumption (i) is usually not satisfied. In Section 6, we show experiments on both discrete and continuous similarities to evaluate the effect of assumption (i).

## 6 Experiments

**Datasets.** In this section, we test our algorithm on two realistic datasets. The first dataset is bidding data from the AAMAS 2015 conference [39]. In this dataset, \(n_{p}=613,n_{r}=201\), and the bidding data has 4 discrete levels: "yes", "maybe", "no" and "conflict". We transform these 4 levels to similarities \(1\), \(\frac{1}{2}\), \(\frac{1}{4}\) and \(0\), as inspired by NeurIPS 2016, in which similarity scores were computed as \(2^{\mathrm{bid}}(0.5s_{\mathrm{text}}+0.5s_{\mathrm{subject}})\)[19]. The transformed dataset satisfies assumption (i) in Theorem 3 as there are only 4 levels. The second dataset contains text-similarity scores recreated from the ICLR 2018 conference with \(n_{p}=911,n_{r}=2435\)[26]. These scores were computed by comparing the text of each paper with the text of each reviewer's past work; we directly use them as the similarity matrix. Assumption (i) is not valid in this dataset as it is continuous-valued. The constraints are set as \(\ell_{p}=3,\ell_{r}=6\) for ICLR 2018 as was done in [26] and \(\ell_{p}=3,\ell_{r}=12\) for AAMAS 2015 for feasibility. In Appendix A.3, we also test our algorithm on four additional datasets from [39].

**Experiment and hyperparameter setting.** We implement PLRA and two versions of PM (PM-E and PM-Q) using commercial optimization solver Gurobi 10.0 [36]. For each algorithm on each dataset, we use a principled method (Appendix A.2) to find 8 sets of hyperparameters that produce solutions with at least \(\{80\%,85\%,90\%,95\%,98\%,99\%,99.5\%,100\%\}\) of the maximum possible quality. When setting the hyperparameters, we choose a "slackness" value \(\delta\) and allow PM to produce solutions with \(\mathrm{Maxprob}\) at most \(\delta\) higher than the optimal \(\mathrm{Maxprob}\) (in exchange for better performance on other metrics). For AAMAS 2015, \(\delta=0.00\) and for ICLR 2018, \(\delta=0.02\). We refer to Appendix A.2 for more details. We do not consider assignments with lower than \(80\%\) of the maximum quality since such low-quality assignments are unlikely to be deployed in practice. We evaluate the produced assignments on different randomness metrics to draw Figs. 2 to 4. We also implemented Algorithm 1 and tested it with the set of parameters at \(95\%\) relative quality to create Table 1. All source code is released at [https://github.com/YixuanEvenXu/perturbed-maximization](https://github.com/YixuanEvenXu/perturbed-maximization), and all experiments are done on a server with 56 cores and 504G RAM, running Ubuntu 20.04.6.

**Comparing Gurobi and Algorithm 1.** Table 1 shows that on ICLR 2018, Gurobi takes less wall clock time than Algorithm 1 due to parallelization over the server's 112 cores. However, Algorithm 1 takes less total CPU time (system + user CPU time) and achieves similar performance with Gurobi, which shows that Algorithm 1 provides decently approximated solutions using fewer computation

\begin{table}
\begin{tabular}{|c||c|c||c|c|} \hline Implementation & \multicolumn{2}{c||}{Gurobi} & \multicolumn{2}{c|}{Flow \((w=10)\)} \\ \hline Algorithm & PM-Q & PM-E & PM-Q & PM-E \\ \hline \hline Wall Clock Time & 86.85s & 368.13s & 563.24s & 554.07s \\ \hline Total CPU Time & 988.11s & 3212.18s & 562.77s & 553.59s \\ \hline \hline Quality & 95\% & 95\% & 94\% & 94\% \\ \hline PQuality & 606.55 & 305.41 & 603.34 & 303.68 \\ \hline AvgMaxp \((\downarrow)\) & 0.87 & 0.87 & 0.86 & 0.86 \\ \hline Entropy \((\uparrow)\) & 1589.95 & 1630.80 & 1575.86 & 1607.20 \\ \hline \end{tabular}
\end{table}
Table 1: Comparison of different implementations on ICLR 2018. Downarrows \((\downarrow)\) mean the lower the better and uparrows \((\uparrow)\) mean the higher the better. Due to parallelization, Gurobi takes less wall clock time. However, the network-flow-based approximation uses fewer computation resources (total CPU time). The approximation has relatively accurate \(\mathrm{Quality}\), \(\mathrm{PQuality}\) and randomness metrics.

resources. Due to the space limit, rows in Table 1 have been selected and only results on ICLR 2018 are present. The complete tables and analysis for both datasets can be found in Appendix A.1.

**Comparing randomness metrics of PM and PLRA on discrete-valued datasets.** As shown in Figs. 1(a) and 3, on AAMAS 2015, both versions of PM achieve exactly the same performance with PLRA on \(\mathrm{Maxprob}\) while improving significantly on the other randomness metrics. Recall that PLRA achieves the optimal quality for a given \(\mathrm{Maxprob}\). This demonstrates that as predicted by Theorem 3, PM produces solutions that are more generally random while preserving the optimality in \(\mathrm{Maxprob}\) on discrete-valued datasets where assumption (i) holds. In Appendix A.3, we also test our algorithm on four more datasets from [39] and observe similar results.

**Comparing randomness metrics of PM and PLRA on continuous-valued datasets.** The results on ICLR 2018 in Figs. 1(b) and 4 show that both versions of PM sacrifice some \(\mathrm{Maxprob}\) as compared to PLRA. The exact amount of this sacrifice is affected by the slackness \(\delta\) described in Appendix A.2. However, the improved randomness is still significant, though to a lesser extent than on AAMAS 2015. Note that assumption (i) of Theorem 3 does not hold on ICLR 2018. This exhibits the empirical efficacy of PM beyond the theoretical guarantees provided in Section 5.

**Comparing randomness metrics of PM-E and PM-Q.** In all of Figs. 2 to 4, we can see that no matter what metric and dataset are used, the performances of PM-E and PM-Q are always similar.

Figure 3: The trade-offs between quality and four randomness metrics on AAMAS 2015. Downarrows (\(\downarrow\)) indicate that lower is better and uparrows (\(\uparrow\)) indicate that higher is better. The figure shows that PM significantly outperforms PLRA on all four metrics, as predicted by Theorem 3.

Figure 2: The trade-offs between quality and \(\mathrm{Maxprob}\) on both datasets. Downarrows (\(\downarrow\)) indicate that lower is better. On AAMAS 2015 where assumption (i) of Theorem 3 holds, PM incurs no increase in \(\mathrm{Maxprob}\); on ICLR 2018 where it does not hold, PM causes a \(0.02\) increase.

This suggests that the specific type of the perturbation function has limited impact as long as it is strictly concave. Therefore, program chairs do not need to carefully consider this choice in practice.

**Additional experiments.** Due to the page limit on the main paper, we are not able to present all the experiments we run in this section. We refer to Appendix A for additional experimental results about the network-flow-based approximation (Appendix A.1), hyperparameter tuning (Appendix A.2) and experiments on more datasets (Appendix A.3).

## 7 Conclusion

We present a general-purpose, practical algorithm for use by conference program chairs in computing randomized paper assignments. We show both theoretically and experimentally that our algorithm significantly improves over the previously deployed randomized assignment algorithm, PLRA. In conferences that currently deploy PLRA, our algorithm can be simply plugged-in in place of it to find a paper assignment with the same quality but with an improved level of randomization, achieving various benefits.

In practice, various aspects of paper assignment other than quality and randomness are considered by program chairs. We refer to Appendix C for discussions about how to optimize a specific metric with our algorithm (Appendix C.1) and how to incorporate some additional constraints from [20] (Appendix C.2). That being said, we do not consider various other aspects and constraints that may be desired by program chairs: e.g., fairness-based objectives [2] or constraints on review cycles [20]. Incorporating these aspects remains an interesting direction for future work.

**Broader Impacts.** We expect our algorithm to have a mostly positive social impact by assisting program chairs in mitigating malicious behavior, facilitating evaluation of assignments, and increasing reviewer diversity and reviewer anonymity. While deploying a randomized assignment may negatively impact the assignment quality as compared to a deterministic assignment, our work allows conferences to choose the level of randomization that they deem best for their goals.

## Acknowledgments and Disclosure of Funding

This work was supported by ONR grant N000142212181 and NSF grant IIS-2200410.

This work was supported in part by the Sloan Research Fellowship.

Figure 4: The trade-offs between quality and four randomness metrics on ICLR 2018. Downarrows (\(\downarrow\)) indicate that lower is better and uparrows (\(\uparrow\)) indicate that higher is better. The figure shows that PM outperforms PLRA on all four metrics despite the fact that assumption (i) of Theorem 3 does not hold, indicating the empirical efficacy of PM beyond theoretical guarantees.

## References

* [1] Laurent Charlin and Richard S. Zemel. The Toronto Paper Matching System: An automated paper-reviewer assignment system. In _ICML Workshop on Peer Reviewing and Publishing Models_, 2013.
* [2] Ivan Stelmakh, Nihar B. Shah, and Aarti Singh. PeerReview4All: Fair and accurate reviewer assignment in peer review. In _ALT_, 2019.
* [3] Steven Jecmen, Hanrui Zhang, Ryan Liu, Fei Fang, Vincent Conitzer, and Nihar B Shah. Near-optimal reviewer splitting in two-phase paper reviewing and conference experiment design. In _HCOMP_, 2022.
* [4] Wenbin Tang, Jie Tang, and Chenhao Tan. Expertise matching via constraint-based optimization. In _International Conference on Web Intelligence and Intelligent Agent Technology_, 2010.
* [5] Peter A. Flach, Sebastian Spiegler, Bruno Golenia, Simon Price, John Guiver, Ralf Herbrich, Thore Graepel, and Mohammed J. Zaki. Novel tools to streamline the conference review process: Experiences from SIGKDD'09. _SIGKDD Explorations Newsletter_, 2010.
* [6] Camillo J. Taylor. On the optimal assignment of conference papers to reviewers. Technical report, Department of Computer and Information Science, University of Pennsylvania, 2008.
* [7] Laurent Charlin, Richard S. Zemel, and Craig Boutilier. A framework for optimizing paper matching. In _UAI_, 2011.
* [8] Nihar B Shah. Challenges, experiments, and computational solutions in peer review. _Communications of the ACM_, 2022.
* [9] David Mimno and Andrew McCallum. Expertise modeling for matching papers with reviewers. In _KDD_, 2007.
* [10] Xiang Liu, Torsten Suel, and Nasir Memon. A robust model for paper reviewer assignment. In _RecSys_, 2014.
* [11] Marko A. Rodriguez and Johan Bollen. An algorithm to determine peer-reviewers. In _CIKM_, 2008.
* [12] Hong Diep Tran, Guillaume Cabanac, and Gilles Hubert. Expert suggestion for conference program committees. In _RCIS_, 2017.
* [13] Judy Goldsmith and Robert H. Sloan. The AI conference paper assignment problem. In _AAAI Workshop_, 2007.
* [14] T. N. Vijaykumar. Potential organized fraud in ACM/IEEE computer architecture conferences. [https://medium.com/@tnvijayk/potential-organized-fraud-in-acm-ieee-computer-architecture-conferences-ccd61169370d](https://medium.com/@tnvijayk/potential-organized-fraud-in-acm-ieee-computer-architecture-conferences-ccd61169370d), 2020. Accessed February 1, 2023.
* [15] Michael Littman. Collusion rings threaten the integrity of computer science research. _Communications of the ACM_, 2021.
* [16] Jef Akst. I hate your paper. Many say the peer review system is broken. Here's how some journals are trying to fix it. _The Scientist_, 2010.
* [17] Edward F. Barroga. Safeguarding the integrity of science communication by restraining 'rational cheating' in peer review. _Journal of Korean Medical Science_, 2014.
* [18] Mario Paolucci and Francisco Grimaldo. Mechanism change in a simulation of peer review: From junk support to elitism. _Scientometrics_, 2014.
* [19] Nihar B Shah, Behzad Tabibian, Krikamol Muandet, Isabelle Guyon, and Ulrike Von Luxburg. Design and analysis of the nips 2016 review process. _Journal of Machine Learning Research_, 2018.

* [20] Kevin Leyton-Brown, Yatin Nandwani, Hedayat Zarkoob, Chris Cameron, Neil Newman, Dinesh Raghu, et al. Matching papers and reviewers at large conferences. _arXiv preprint arXiv:2202.12273_, 2022.
* [21] Martin Saveski, Steven Jecmen, Nihar Shah, and Johan Ugander. Counterfactual evaluation of peer review assignment strategies in computer science and artificial intelligence. In _NeurIPS_, 2023.
* [22] Steven Jecmen, Hanrui Zhang, Ryan Liu, Nihar Shah, Vincent Conitzer, and Fei Fang. Mitigating manipulation in peer review via randomized reviewer assignments. In _NeurIPS_, 2020.
* [23] Eric Budish, Yeon-Koo Che, Fuhito Kojima, and Paul Milgrom. Implementing random assignments: A generalization of the Birkhoff-von Neumann theorem. In _Cowles Summer Conference_, 2009.
* [24] OpenReview.net. OpenReview matcher. [https://github.com/openreview/openreview-matcher](https://github.com/openreview/openreview-matcher), 2023. Accessed April 2023.
* [25] Komal Dhull, Steven Jecmen, Pravesh Kothari, and Nihar B Shah. Strategyproofing peer assessment via partitioning: The price in terms of evaluators' expertise. In _HCOMP_, 2022.
* [26] Yichong Xu, Han Zhao, Xiaofei Shi, Jeremy Zhang, and Nihar B Shah. On strategyproof conference peer review. In _IJCAI_, 2019.
* [27] Steven Jecmen, Nihar B Shah, Fei Fang, and Vincent Conitzer. Tradeoffs in preventing manipulation in paper bidding for reviewer assignment. In _ML Evaluation Standards Workshop at ICLR_, 2022.
* [28] Steven Jecmen, Minji Yoon, Vincent Conitzer, Nihar B. Shah, and Fei Fang. A dataset on malicious paper bidding in peer review. In _WWW_, 2023.
* [29] Ruihan Wu, Chuan Guo, Felix Wu, Rahul Kidambi, Laurens Van Der Maaten, and Kilian Weinberger. Making paper reviewing robust to bid manipulation attacks. In _ICML_, 2021.
* [30] Niclas Boehmer, Robert Bredereck, and Andre Nichterlein. Combating collusion rings is hard but possible. In _AAAI_, 2022.
* [31] Andrew Tomkins, Min Zhang, and William D. Heavlin. Reviewer bias in single- versus double-blind peer review. _Proceedings of the National Academy of Sciences_, 2017.
* [32] Neil D. Lawrence. The NIPS experiment. [https://inverseprobability.com/2014/12/16/the-nips-experiment](https://inverseprobability.com/2014/12/16/the-nips-experiment), 2014. Accessed February 1, 2023.
* [33] Eric Price. The NIPS experiment. [http://blog.mrtz.org/2014/12/15/the-nips-experiment.html](http://blog.mrtz.org/2014/12/15/the-nips-experiment.html), 2014. Accessed February 1, 2023.
* [34] Ivan Stelmakh, Charvi Rastogi, Nihar B Shah, Aarti Singh, and Hal Daume III. A large scale randomized controlled trial on herding in peer-review discussions. _PLoS ONE_, 2023.
* [35] Alina Beygelzimer, Yann Dauphin, Percy Liang, and Jennifer Wortman Vaughan. The NeurIPS 2021 consistency experiment. [https://blog.neurips.cc/2021/12/08/the-neurips-2021-consistency-experiment/](https://blog.neurips.cc/2021/12/08/the-neurips-2021-consistency-experiment/), 2021. Accessed February 1, 2023.
* [36] Gurobi Optimization, L.L.C. Gurobi Optimizer Reference Manual, 2023.
* [37] Jack Edmonds and Richard M Karp. Theoretical improvements in algorithmic efficiency for network flow problems. _Journal of the ACM (JACM)_, 1972.
* [38] Michael B Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matrix multiplication time. _Journal of the ACM (JACM)_, 2021.
* [39] Nicholas Mattei and Toby Walsh. Preflib: A library for preferences [http://www.preflib.org](http://www.preflib.org). In _ADT_, 2013.

Additional Experiments

### Network-Flow-Based Approximation

In Section 6, we presented Table 1, which is a shortened version of the experimental results comparing Gurobi and Algorithm 1. We now present the complete experimental results on both datasets in Tables 2 and 3 as well as the complete analysis in this section.

**Comparing the solution qualities of Gurobi and Algorithm 1.** In the rows about \(\mathrm{Quality}\) and \(\mathrm{PQuality}\) in Tables 2 and 3, we can see that Algorithm 1 has almost the same \(\mathrm{Quality}\) as Gurobi. The \(\mathrm{PQuality}\) of Algorithm 1 is also close to Gurobi's. This shows that with \(w=10\), Algorithm 1 approximates PM in solution quality well, validating Theorem 1.

**Comparing the randomness metrics of Gurobi and Algorithm 1.** As shown in Table 2, for randomness metrics \(\mathrm{Maxprob}\), \(\mathrm{AvgMaxp}\), and \(\mathrm{L2Norm}\), the approximated solution by Algorithm 1 has a similar or identical performance to Gurobi on AAMAS 2015. For \(\mathrm{Support}\) and \(\mathrm{Entropy}\), the approximated solution is significantly worse than Gurobi's, but it is still significantly better than PLRA's solution. As presented in Table 3, on ICLR 2018, the performances of Algorithm 1 and Gurobi on all randomness metrics are relatively close. This shows that Algorithm 1 mostly preserves PM's performance on randomness metrics. Although on discrete-valued datasets like AAMAS 2015, \(\mathrm{Support}\) and \(\mathrm{Entropy}\) can be affected, they are still better than PLRA's solution.

### Hyperparameter Tuning

In this section, we will introduce the way in which we do hyperparameter tuning for PM. We start with a lemma that shows the monotonicity of the solution quality of PM-Q with respect to \(\beta\).

**Lemma A.1**.: _For an input instance \((n_{p},n_{r},\ell_{p},\ell_{r},\mathbf{S})\), let the solution of PM with \(f_{1}(x)=x-\beta_{1}x^{2}\) be \(\mathbf{x}_{1}\) and the solution of PM with \(f_{2}(x)=x-\beta_{2}x^{2}\) be \(\mathbf{x}_{2}\) where \(\beta_{1},\beta_{2}\in[0,1]\). Then_

\[\beta_{1}<\beta_{2}\implies\mathrm{Quality}(\mathbf{x}_{1})\geq\mathrm{Quality }(\mathbf{x}_{2}).\]

**Proof of Lemma a.1:** Let \(\mathrm{SQuality}(\mathbf{x})=\sum_{p}\sum_{r}x_{p,r}^{2}S_{p,r}\). Then

\[\mathrm{PQuality}_{f_{1}}(\mathbf{x}) =\mathrm{Quality}(\mathbf{x})-\beta_{1}\mathrm{SQuality}(\mathbf{ x}),\] \[\mathrm{PQuality}_{f_{2}}(\mathbf{x}) =\mathrm{Quality}(\mathbf{x})-\beta_{2}\mathrm{SQuality}(\mathbf{ x}).\]

As \(\mathbf{x}_{1}\) maximizes \(\mathrm{PQuality}_{f_{1}}(\mathbf{x})\) and \(\mathbf{x}_{2}\) maximizes \(\mathrm{PQuality}_{f_{2}}(\mathbf{x})\), we have

\[\mathrm{Quality}(\mathbf{x}_{1})-\beta_{1}\mathrm{SQuality}( \mathbf{x}_{1})\geq\mathrm{Quality}(\mathbf{x}_{2})-\beta_{1}\mathrm{SQuality}( \mathbf{x}_{2}), \tag{1}\] \[\mathrm{Quality}(\mathbf{x}_{1})-\beta_{2}\mathrm{SQuality}( \mathbf{x}_{1})\leq\mathrm{Quality}(\mathbf{x}_{2})-\beta_{2}\mathrm{SQuality}( \mathbf{x}_{2}). \tag{2}\]

Subtracting (2) from (1), and using \(\beta_{2}>\beta_{1}\), we have

\[(\beta_{2}-\beta_{1})\mathrm{SQuality}(\mathbf{x}_{1})\geq(\beta_{2}-\beta_{1 })\mathrm{SQuality}(\mathbf{x}_{2})\implies\mathrm{SQuality}(\mathbf{x}_{1}) \geq\mathrm{SQuality}(\mathbf{x}_{2}).\]

Then, from (1), we know that

\[\mathrm{Quality}(\mathbf{x}_{1})-\mathrm{Quality}(\mathbf{x}_{2})\geq\beta_{1 }(\mathrm{SQuality}(\mathbf{x}_{1})-\mathrm{SQuality}(\mathbf{x}_{2}))\geq 0.\]

Therefore, \(\mathrm{Quality}(\mathbf{x}_{1})\geq\mathrm{Quality}(\mathbf{x}_{2})\). \(\blacksquare\)

With Lemma A.1, for a minimum requirement of quality \(\mathrm{Quality}_{M}\), we can use binary search to find the largest \(\beta\) for PM-Q such that PM-Q with \(f(x)=x-\beta x^{2}\) gives an assignment with quality \(\geq\mathrm{Quality}_{M}\). Formally, consider the following Algorithm 2.

```
For a given minimum quality requirement \(\mathrm{Quality}_{M}\) and a slackness \(\delta\): 1. Use binary search to find \(Q_{\mathrm{PLRA}}\), the smallest \(Q\) with which PLRA gives a solution with quality \(\geq\mathrm{Quality}_{M}\). 2. Use binary search to find \(\beta_{\mathrm{max}}\), the largest \(\beta\) such that PM-Q with \(Q=Q_{\mathrm{PLRA}}+\delta\) and \(f(x)=x-\beta^{2}\) gives a solution with quality \(\geq\mathrm{Quality}_{M}\). 3. Finalize the hyperparameters as \((Q,\beta)=(\min\{Q_{\mathrm{PLRA}}+\delta,1\},\beta_{\mathrm{max}})\).
```

**Algorithm 2** Hyperparameter Tuning for PM-Q

Algorithm 2 maximizes the parameter \(\beta\) while ensuring the produced assignment with the set of hyperparameters \((Q,\beta)\) has quality at least \(\mathrm{Quality}_{M}\) and \(\mathrm{Maxprob}\) at most \(Q_{\mathrm{PLRA}}+\delta\). Note that any solution with quality \(\geq\mathrm{Quality}_{M}\) has a \(\mathrm{Maxprob}\geq Q_{\mathrm{PLRA}}\). Intuitively, Algorithm 2 istrying to maximize the randomness while obtaining the minimum required quality and near-optimal \(\mathrm{Maxprob}\) given the quality constraint.

Analogously, we use a similar method for tuning the hyperparameters in PM-E.

**Algorithm 3**: Hyperparameter Tuning for PM-E

For a given minimum quality requirement \(\mathrm{Quality}_{M}\) and a slackness \(\delta\):

1. Use binary search to find \(Q_{\mathrm{PLRA}}\), the smallest \(Q\) with which PLRA gives a solution with quality \(\geq\mathrm{Quality}_{M}\).
2. Use binary search to find \(\alpha_{\max}\), the largest \(\alpha\) such that PM-E with \(Q=Q_{\mathrm{PLRA}}+\delta\) and \(f(x)=1-e^{-\alpha x}\) gives a solution with quality \(\geq\mathrm{Quality}_{M}\).
3. Finalize the hyperparameters as \((Q,\alpha)=(\min\{Q_{\mathrm{PLRA}}+\delta,1\},\alpha_{\max})\).

Although we similarly apply binary search to PM-E as we have done to PM-Q, the monotonicity condition of Lemma A.1 does not hold in general for PM-E. For instance, consider the following Example 1. If we run PM-E with different \(\alpha\) and \(Q=1\), the solution quality is not monotonic with respect to \(\alpha\). The results are shown in Fig. 5.

**Example 1**.: _In this example, \(n_{p}=n_{r}=3\), \(\ell_{p}=\ell_{r}=1\) and_

\[\mathbf{S}=\begin{pmatrix}0.4&0.0&0.6\\ 0.8&0.6&0.0\\ 0.8&0.6&1.0\end{pmatrix}\]

Nevertheless, such examples are rare in practice. We have examined thousands of examples to find Example 1. In fact, the monotonicity of solution quality with respect to \(\alpha\) can still be observed empirically in the datasets we used. Therefore, for the purpose of our experiments in Section 6, we will still use Algorithm 3 to tune the hyperparameters of PM-E.

In Algorithms 2 and 3, there are still two parameters to be fixed, namely \(\delta\) and \(\mathrm{Quality}_{M}\). In Section 6, \(\mathrm{Quality}_{M}\) was already specified as \(\{80\%,85\%,90\%,95\%,98\%,99\%,99.5\%,100\%\}\) of the maximum possible quality. It remains to specify \(\delta\). For experiments in Section 6, we used \(\delta=0\) for AAMAS 2015 and \(\delta=0.02\) for ICLR 2018. In the rest of the section, we will show experiments about the performances of PM-Q and PM-E with different \(\delta\) values to justify our choice. In practice, conference program chairs can simply choose a small value for the slackness, such as \(\delta=0.02\).

Figure 5: The quality of PM-E on Example 1 with \(Q=1\) and different \(\alpha\). The figure shows that the solution quality of PM-E is not necessarily monotonic with respect to \(\alpha\).

As we increase \(\delta\), we allow PM-Q and PM-E to find more random solutions (i.e., solutions that perform better on our randomness metrics) at a cost of larger \(\mathrm{Maxprob}\). To balance the gain and loss, we choose \(\delta\) that maximizes a linear combination of them. We call these \(\delta\)**elbow points**. Below, we show the choices of \(\delta\) graphically in Figs. 6 and 7.

As shown in Figs. 6 and 7, on AAMAS 2015, the elbow points of both algorithms in all four metrics are at \(\delta=0\). Therefore, we should set \(\delta=0\) for it. On ICLR 2018, the elbow points lie in the range \(\delta\in[0.02,0.04]\). We have chosen \(\delta=0.02\) in this range for it.

Figure 6: The performances of PM-Q and PM-E on AAMAS 2015 with different \(\delta\). \(\mathrm{Quality}_{M}\) is set to \(95\%\) of the maximum possible quality. Downarrows (\(\downarrow\)) mean the lower the better and uparrows (\(\uparrow\)) mean the higher the better. The figure shows that the elbow points of both algorithms in all four metrics are at \(\delta=0\). Therefore, we should set \(\delta=0\) for AAMAS 2015.

Figure 7: The performances of PM-Q and PM-E on ICLR 2018 with different \(\delta\). \(\mathrm{Quality}_{M}\) is set to \(95\%\) of the maximum possible quality. Downarrows (\(\downarrow\)) mean the lower the better and uparrows (\(\uparrow\)) mean the higher the better. The figure shows that the elbow points of both algorithms lie in the range \(\delta\in[0.02,0.04]\). We have chosen \(\delta=0.02\) in this range.

### Experiments on More Datasets

In this subsection, we include additional experiment results on more \(4\) datasets. In particular, we include Preflib1 (00039-1 from [39], \(n_{p}=54,n_{r}=31\)), Preflib2 (00039-2 from [39], \(n_{p}=52,n_{r}=24\)), Preflib3 (00039-3 from [39], \(n_{p}=176,n_{r}=146\)) and AAMAS 2016 (00037-2 from [39], \(n_{p}=442,n_{r}=161\)). All of the four datasets are bidding data consisting of \(4\) discrete levels: "yes", "maybe", "no" and "conflict". We transform these 4 levels to similarities \(1\), \(\frac{1}{2},\frac{1}{4}\) and \(0\) as done in Section 6. The constraints are set as \(\ell_{p}=3,\ell_{r}=6\) for Preflib1 and Preflib3. For Preflib2 and AAMAS 2016, \((\ell_{p},\ell_{r})\) are set as \((3,7)\) and \((3,12)\) respectively for feasibility.

We use the same experimental setup and hyperparameter setting as in Section 6. The results are shown in Fig. 8. The results of these additional datasets are similar to those on AAMAS 2015 shown in Figs. 1(a) and 3. In particular, both versions of PM achieve exactly the same performance with PLRA on \(\mathrm{Maxprob}\) while improving significantly on the other randomness metrics. This shows that the empirical observations in Section 6 are not dataset-specific and generalize to other datasets.

Figure 8: The trade-offs between quality and five randomness metrics on Preflib1, Preflib2, Preflib3 and AAMAS 2016. Downarrows (\(\downarrow\)) indicate that lower is better and uparrows (\(\uparrow\)) indicate that higher is better. The figure shows that PM incurs no increase in \(\mathrm{Maxprob}\) while significantly improves over PLRA on all other four metrics. The results are similar to those on AAMAS 2015 shown in Section 6.

Missing Proofs in Sections 4 and 5

### Proof of Theorem 1

**Theorem 1**.: _Let \(w\in\mathbb{N}^{+}\) be the precision in Algorithm 1, and \(\mathrm{OPT}\) be the optimal perturbed quality._

1. _Algorithm 1 runs in_ \(O(w\cdot\ell_{p}\cdot{n_{p}}^{2}\cdot n_{r})\) _time._
2. _Algorithm 1 returns an assignment with perturbed quality_ \(\mathrm{ALG}\geq\mathrm{OPT}-f(\frac{1}{w})\sum_{p,r}S_{p,r}\)_._

Proof of Theorem 1:.: For (a), consider implementing the maximum cost flow using Edmonds & Karp's Algorithm B in [37]. In Edmonds & Karp's algorithm, we will compute the shortest path on the residual graph each time we find an augmenting path. The number of times we augment is bounded by \(O(w\cdot\ell_{p}\cdot n_{p})\). For the shortest path part, Edmonds & Karp's algorithm applies a node potential trick that ensures the edge weights are non-negative throughout the execution, so that we can use Dijkstra's algorithm for shortest path. Although for each paper \(p\) and reviewer \(r\), \(v_{p}\) and \(v_{r}\) are connected by \(O(w)\) edges, only 2 of them need to be considered: the ones with the largest cost in both directions \(v_{p}\to v_{r}\) and \(v_{r}\to v_{p}\). Therefore, the shortest path can be computed in \(O(n_{p}\cdot n_{r})\) time. Step (6) of Algorithm 1 can be done in \(O(n_{p}\cdot n_{r})\) time by maintaining running totals for each reviewer and paper load. And thus Algorithm 1 runs in \(O(w\cdot\ell_{p}\cdot{n_{p}}^{2}\cdot n_{r})\) time.

For (b), let \(\mathbf{x}^{*}\) be the optimal assignment such that \(\mathrm{PQuality}_{f}(\mathbf{x}^{*})=\mathrm{OPT}\). Consider another assignment \(\mathbf{x}^{\prime}\), where \(x^{\prime}_{p,r}=\frac{1}{w}\lfloor w\cdot x^{*}_{p,r}\rfloor,\forall p\in \mathcal{P},r\in\mathcal{R}\). Note that \(\mathbf{x}^{\prime}\) may not be a feasible assignment if \(\sum_{r}x^{\prime}_{p,r}\leq\ell_{p}\) for some paper \(p\), but any feasible assignment \(\mathbf{x}^{\prime\prime}\) where \(x^{\prime\prime}_{p,r}\geq x^{\prime}_{p,r}\) for all \((p,r)\) will have perturbed quality at least \(\mathrm{PQuality}_{f}(\mathbf{x}^{\prime})\). Then \(x^{*}_{p,r}-x^{\prime}_{p,r}\in[0,\frac{1}{w}]\), and

\[\mathrm{PQuality}_{f}(\mathbf{x}^{*})-\mathrm{PQuality}_{f}(\mathbf{x}^{ \prime})=\sum_{p,r}S_{p,r}\cdot[f(x^{*}_{p,r})-f(x^{\prime}_{p,r})]\leq f( \frac{1}{w})\sum_{p,r}S_{p,r}. \tag{3}\]

On the other hand, \(\mathbf{x}^{\prime}\) corresponds to a feasible flow for the maximum-cost flow problem in Step (5) of Algorithm 1. Therefore, \(\mathrm{ALG}\geq\mathrm{PQuality}_{f}(\mathbf{x}^{\prime})\). Together with (3), we have \(\mathrm{ALG}\geq\mathrm{OPT}-f(\frac{1}{w})\sum_{p,r}S_{p,r}\). 

### Proof of Theorem 2

**Theorem 2**.: _For an input instance \((n_{p},n_{r},\ell_{p},\ell_{r},\mathbf{S})\), where \(\mathbf{S}\) is blockwise dominant with block identity \(\mathbf{A}\in\mathbb{R}_{\geq 0}^{k\times k}\) and block sizes \(\{p_{1},\ldots,p_{k}\},\{r_{1},\ldots,r_{k}\}\), assume (i) \(\{r_{1},\ldots,r_{k}\}\) are not all equal, (ii) \(p_{i}\cdot\ell_{p}\leq r_{i}\cdot\ell_{r}\)\(\forall i\in\{1,\ldots,k\}\) and (iii) \(Q\cdot r_{i}\geq\ell_{p}\)\(\forall i\in\{1,\ldots,k\}\). Let \(f\) be a strictly concave perturbation function and \(f^{\prime}(0)<\mathrm{Dom}(\mathbf{A})f^{\prime}(1)\). PM with \(f(x)\) as the perturbation function (weakly) dominates PLRA in quality and all randomness metrics. Formally,_

1. \(\forall\mathbf{x}\in\mathrm{PM}(Q,f)\)_,_ \(\forall\mathbf{y}\in\mathrm{PLRA}(Q)\)_,_ \[\mathrm{Quality}(\mathbf{x})\geq\mathrm{Quality}(\mathbf{y}), \quad\mathrm{Maxprob}(\mathbf{x})\leq\mathrm{Maxprob}(\mathbf{y}),\quad \mathrm{AvgMaxp}(\mathbf{x})\leq\mathrm{AvgMaxp}(\mathbf{y}),\] \[\mathrm{L2Norm}(\mathbf{x})\leq\mathrm{L2Norm}(\mathbf{y}), \quad\mathrm{Entropy}(\mathbf{x})\geq\mathrm{Entropy}(\mathbf{y}),\quad\quad \mathrm{Support}(\mathbf{x})\geq\mathrm{Support}(\mathbf{y}).\]
2. \(\forall\mathbf{x}\in\mathrm{PM}(Q,f)\)_,_ \(\exists\mathbf{y}\in\mathrm{PLRA}(Q)\)_,_ \[\mathrm{AvgMaxp}(\mathbf{x})<\mathrm{AvgMaxp}(\mathbf{y}), \quad\mathrm{L2Norm}(\mathbf{x})<\mathrm{L2Norm}(\mathbf{y}),\quad\mathrm{ Entropy}(\mathbf{x})>\mathrm{Entropy}(\mathbf{y}).\]

Proof of Theorem 2:.: Label the first \(p_{1}\) papers and \(r_{1}\) reviewers as group 1, the next \(p_{2}\) papers and \(r_{2}\) reviewers as group \(2\), the next \(p_{3}\) papers and \(r_{3}\) reviewers as group \(3\) and so on.

For convenience of language, for an assignment \(\mathbf{x}\), define **the total**\(\mathrm{Quality}\)**of paper**\(p\) to be \(\sum_{r}x_{p,r}S_{p,r}\) and **the total**\(\mathrm{PQuality}_{f}\)**of paper**\(p\) to be \(\sum_{r}f(x_{p,r})S_{p,r}\).

Define \(\mathbf{x}^{*}\) to be the assignment such that for each paper \(p\) and reviewer \(r\), \(x^{*}_{p,r}=\ell_{p}/r_{i}\) if they are in the same group \(i\) and \(x^{*}_{p,r}=0\) otherwise. Note that \(x^{*}\) is feasible, because \(\ell_{p}/r_{i}\leq Q\) according to assumption (iii), each row of \(\mathbf{x}^{*}\) sums to \(\ell_{p}\) and each column of \(x^{*}\) sums \(\leq\ell_{r}\) according to assumption (ii). Intuitively, \(x^{*}\) is a generalized version of Fig. 0(a) on blockwise dominant matrices.

**Claim B.2.1**.: _For feasible assignment \(\mathbf{x}\), \(\mathrm{Quality}(\mathbf{x}^{*})\geq\mathrm{Quality}(\mathbf{x})\). The equality holds if and only if \(\mathbf{x}\) assigns paper \(p\) to reviewer \(r\) with positive probability only when they are in the same group._

**Proof of Claim B.2.1:** First, \(\mathrm{Quality}(\mathbf{x}^{*})=\sum_{i=1}^{k}p_{i}r_{i}\cdot\ell_{p}/r_{i} \cdot A_{i,i}=\sum_{i=1}^{k}p_{i}\cdot\ell_{p}\cdot A_{i,i}\).

On the other hand, recall that \(A_{i,i}>A_{i,j},\forall j\neq i\). For a paper \(p\) in group \(i\), \(p\) can only be assigned to \(\ell_{p}\) reviewers, so the total similarity is at most \(\ell_{p}\cdot A_{i,i}\). Therefore, \(\mathrm{Quality}(\mathbf{x})\leq\sum_{i=1}^{k}p_{i}\cdot\ell_{p}\cdot A_{i,i}= \mathrm{Quality}(\mathbf{x}^{*})\). The equality holds if and only if each paper in group \(i\) is assigned to \(\ell_{p}\) reviewers with \(A_{i,i}\) similarity, i.e., \(\ell_{p}\) reviewers in the same group. \(\blacksquare\)

As PLRA is maximizing \(\mathrm{Quality}\) and \(x^{*}\) is a feasible solution, we have the following corollary.

**Corollary B.2.1**.: \(\forall\mathbf{x}\in\mathrm{PLRA}(Q)\)_, \(\mathbf{x}\) assigns paper \(p\) to reviewer \(r\) with positive probability if and only if they are in the same group._

Next, we consider the performance of PM.

**Claim B.2.2**.: \(\mathrm{PM}(Q,f)=\{\mathbf{x}^{*}\}\)_._

**Proof of Claim B.2.2:** First, \(A_{i,i}\geq\mathrm{Dom}(\mathbf{A})A_{i,j},\forall j\neq i\) by the definition of \(\mathrm{Dom}(\mathbf{A})\).

For a paper \(p\) in group \(i\), consider the maximum total \(\mathrm{PQuality}_{f}\) of \(p\). For some assignment \(\mathbf{x}\), suppose \(\mathbf{x}\) assigns \(p\) to some reviewer \(r\) in group \(j\neq i\) with probability \(\tau\). If we adjust \(\mathbf{x}\) so that the probability \(\tau\) is instead assigned to reviewers in group \(i\), then the \(\mathrm{PQuality}_{f}\) will first decrease by \(f(\tau)\cdot A_{i,j}\leq\tau f^{\prime}(0)A_{i,j}\) and then increase by at least \(\tau f^{\prime}(1)A_{i,i}\). As \(f^{\prime}(0)<\mathrm{Dom}(\mathbf{A})f^{\prime}(1)\),

\[\tau f^{\prime}(1)A_{i,i}-\tau f^{\prime}(0)A_{i,j}>\tau f^{\prime}(1)(A_{i,i} -\mathrm{Dom}(\mathbf{A})A_{i,j})\geq 0.\]

This shows that the adjustment increases the total \(\mathrm{PQuality}_{f}\) of \(p\). Therefore, to maximize the total \(\mathrm{PQuality}_{f}\) of \(p\), \(p\) should only be assigned to reviewers in group \(i\). Let \(p\) be assigned to the \(j\)-th reviewer in group \(i\) with probability \(\alpha_{j}\) (\(\sum_{j}\alpha_{j}=\ell_{p}\)), then the total \(\mathrm{PQuality}_{f}\) of \(p\) equals

\[\sum_{j=1}^{r_{i}}f(\alpha_{j})\cdot A_{i,i}. \tag{4}\]

According to Jensen's inequality, only \(\alpha_{j}=\frac{\ell_{p}}{r_{i}},\forall j\) maximizes (4). This shows that, for every paper \(p\), the corresponding row of \(\mathbf{x}^{*}\) is the unique assignment that maximizes the total \(\mathrm{PQuality}_{f}\) of \(p\). And thus \(\mathbf{x}^{*}\) is the unique solution that maximizes the overall \(\mathrm{PQuality}_{f}\). \(\blacksquare\)

Now we are ready to proceed to prove Theorem 2. Note that Claim B.2.2 shows that the only possible solution of PM is \(\mathbf{x}^{*}\). For clearer presentation, let \(\mathbf{x}^{(\mathrm{PM})}=\mathbf{x}^{*}\).

For \(\mathrm{Quality}\), Claim B.2.1 implies \(\forall\mathbf{x}^{(\mathrm{PLRA})}\in\mathrm{PLRA}(Q)\), \(\mathrm{Quality}(\mathbf{x}^{(\mathrm{PM})})\geq\mathrm{Quality}(\mathbf{x}^{ (\mathrm{PLRA})})\).

For \(\mathrm{Maxprob}\), compute that \(\mathrm{Maxprob}(\mathbf{x}^{(\mathrm{PM})})=\max_{i}\{\ell_{p}/r_{i}\}\). On the other hand, Corollary B.2.1 implies that \(\forall\mathbf{x}^{(\mathrm{PLRA})}\in\mathrm{PLRA}(Q)\), \(\mathrm{Maxprob}(\mathbf{x}^{(\mathrm{PLRA})})\geq\max_{i}\{\ell_{p}/r_{i}\}= \mathrm{Maxprob}(\mathbf{x}^{(\mathrm{PM})})\).

For \(\mathrm{Support}\), compute that \(\mathrm{Support}(\mathbf{x}^{(\mathrm{PM})})=\sum_{i=1}^{k}p_{i}r_{i}\). On the other hand, Corollary B.2.1 implies that \(\forall\mathbf{x}^{(\mathrm{PLRA})}\in\mathrm{PLRA}(Q)\), \(\mathrm{Support}(\mathbf{x}^{(\mathrm{PLRA})})\leq\sum_{i=1}^{k}p_{i}r_{i}= \mathrm{Support}(\mathbf{x}^{(\mathrm{PM})})\).

For the other metrics, \(\mathrm{AvgMaxp}\), Entropy and \(\mathrm{L2Norm}\), consider a paper \(p\) in group \(i\). By Corollary B.2.1, we know that PLRA only assigns \(p\) to reviewers in group \(i\). Let it be assigned to the \(j\)-th reviewer in group \(i\) with probability \(\alpha_{j}\) (\(\sum_{j}\alpha_{j}=\ell_{p}\)). Note that \(\max_{j}\{\alpha_{j}\}\) is minimized by \(\alpha_{j}=\frac{\ell_{p}}{r_{i}},\forall j\), which is the corresponding row in \(x^{(\mathrm{PM})}\) for each \(p\). Meanwhile, according to Jensen's inequality, \(\sum_{j}\alpha_{j}^{2}\) is minimized by \(\alpha_{j}=\frac{\ell_{p}}{r_{i}},\forall j\) and \(\sum_{j}\alpha_{j}\ln(1/\alpha_{j})\) is maximized by \(\alpha_{j}=\frac{\ell_{p}}{r_{i}},\forall j\). So \(\forall\mathbf{x}^{(\mathrm{PLRA})}\in\mathrm{PLRA}(Q)\), \(\mathrm{AvgMaxp}(\mathbf{x}^{(\mathrm{PM})})\leq\mathrm{AvgMaxp}(\mathbf{x}^{ (\mathrm{PLRA})})\), \(\mathrm{L2Norm}(\mathbf{x}^{(\mathrm{PM})})\leq\mathrm{L2Norm}(\mathbf{x}^{( \mathrm{PLRA})})\) and \(\mathrm{Entropy}(\mathbf{x}^{(\mathrm{PM})})\geq\mathrm{Entropy}(\mathbf{x}^{( \mathrm{PLRA})})\). Moreover, as \(\{r_{1},\ldots,r_{k}\}\) are not all the same, for some group \(i\), \(\frac{\ell_{p}}{r_{i}}<\max_{j}\{\frac{\ell_{p}}{r_{j}}\}\leq Q\). For this group, \(\alpha_{j}=\frac{\ell_{p}}{r_{i}},\forall j\) is not the only solution. Thus, \(\exists\mathbf{x}^{(\mathrm{PLRA})}\in\mathrm{PLRA}(Q)\), \(\mathrm{AvgMaxp}(\mathbf{x}^{(\mathrm{PM})})<\mathrm{AvgMaxp}(\mathbf{x}^{( \mathrm{PLRA})})\), \(\mathrm{L2Norm}(\mathbf{x}^{(\mathrm{PM})})<\mathrm{L2Norm}(\mathbf{x}^{( \mathrm{PLRA})})\) and \(\mathrm{Entropy}(\mathbf{x}^{(\mathrm{PM})})>\mathrm{Entropy}(\mathbf{x}^{( \mathrm{PLRA})})\).

This concludes the proof of Theorem 2

### Proof of Theorem 3

**Theorem 3**.: _For an input instance \((n_{p},n_{r},\ell_{p},\ell_{r},\mathbf{S})\), where each entry of \(\mathbf{S}\) is i.i.d. sampled from \(\{v_{1},\ldots,v_{k}\}\)\((0<v_{1}<\cdots<v_{k})\) uniformly, assume (i) \(k\leq\frac{1}{c}\cdot n_{p}\), (ii) \(\ell_{r}\geq c\cdot\ln(n_{r})\), (iii) \(2\cdot n_{p}\cdot\ell_{p}\leq n_{r}\cdot\ell_{r}\) and (iv) \(Q\cdot(n_{r}-1)\geq\ell_{p}\). Let \(f\) be a strictly concave perturbation function and \(f^{\prime}(0)<\frac{v_{r}}{v_{i-1}}f^{\prime}(1),\forall i\in\{2,\ldots,k\}\). With probability \(1-e^{-\Omega(c)}\), PM with \(f(x)\) as the perturbation function (weakly) dominates PLRA in quality and all randomness metrics. Formally,_

1. \(\forall\mathbf{x}\in\mathrm{PM}(Q,f)\)_,_ \(\forall\mathbf{y}\in\mathrm{PLRA}(Q)\)_,_ \[\mathrm{Quality}(\mathbf{x})\geq\mathrm{Quality}(\mathbf{y}), \quad\mathrm{Maxprob}(\mathbf{x})\leq\mathrm{Maxprob}(\mathbf{y}),\quad\mathrm{ AvgMaxp}(\mathbf{x})\leq\mathrm{AvgMaxp}(\mathbf{y}),\] \(\mathrm{L2Norm}(\mathbf{x})\leq\mathrm{L2Norm}(\mathbf{y}),\quad \mathrm{Entropy}(\mathbf{x})\geq\mathrm{Entropy}(\mathbf{y}),\quad\mathrm{ Support}(\mathbf{x})\geq\mathrm{Support}(\mathbf{y}).\)__
2. \(\forall\mathbf{x}\in\mathrm{PM}(Q,f)\)_,_ \(\exists\mathbf{y}\in\mathrm{PLRA}(Q)\)_,_ \[\mathrm{Support}(\mathbf{x})>\mathrm{Support}(\mathbf{y}),\quad\mathrm{L2Norm}( \mathbf{x})<\mathrm{L2Norm}(\mathbf{y}),\quad\mathrm{Entropy}(\mathbf{x})> \mathrm{Entropy}(\mathbf{y}).\]

**Proof of Theorem 3:** To prove this statement, first consider the following 2 algorithms.

**Algorithm 4**: Greedy

For each paper \(p\), let the reviewers sorted by decreasing similarity with \(p\) be \(\{r_{1},r_{2},\ldots,r_{n_{r}}\}\).

Greedily assign \(p\) to the first few reviewers as follows: assign \(p\) to \(r_{1},r_{2},\cdots,r_{\lfloor\ell_{p}/Q\rfloor}\) with probability \(Q\), and assign \(p\) to \(r_{\lfloor\ell_{p}/Q\rfloor+1}\) with probability \(\ell_{p}-Q\lfloor\ell_{p}/Q\rfloor\).

**Algorithm 5**: Balanced Greedy

For each paper \(p\), suppose \(\forall i\in\{1,2,\ldots,k\}\) the set of reviewers with similarity \(v_{i}\) is \(R_{p,i}\).

Initialize remaining paper requirement \(\ell_{\mathrm{remain}}=\ell_{p}\). For \(i\) from \(k\) to 1:

* If \(\ell_{\mathrm{remain}}\geq Q\cdot|R_{p,i}|\), assign \(p\) to each reviewer in \(R_{p,i}\) with probability \(Q\).
* Otherwise uniformly assign \(p\) to each reviewer in \(R_{p,i}\) with probability \(\ell_{\mathrm{remain}}/|R_{p,i}|\).
* Update \(\ell_{\mathrm{remain}}\) to the current remaining paper requirement \(\max\left(0,\ell_{\mathrm{remain}}-Q|R_{p,i}|\right)\).

Note that Balanced Greedy is almost the same algorithm as Greedy, except that Balanced Greedy groups reviewers with the same similarity \(v_{i}\) with \(p\) together as \(R_{p,i}\) and always assigns the same probability to them, while Greedy treats each reviewer individually.

These two Greedies do not always produce feasible assignments because they both consider each paper \(p\) individually and do not take the constraint that each reviewer is assigned at most \(\ell_{r}\) papers into account. Nevertheless, we will show that with high probability, they are feasible, and if this is the case, we can relate them to PM & PLRA and prove the Theorem 3.

At a high level, we will prove the Theorem 3 with the following steps.

1. Greedy and Balanced Greedy are feasible with probability \(1-e^{-\Omega(c)}\).
2. When Greedy and Balanced Greedy are feasible: * Greedy produces a possible solution from PLRA. * PM does exactly the same with Balanced Greedy.
3. Balanced Greedy dominates Greedy with probability \(1-e^{-\Omega(c)}\).

We will formalize and prove the above 3 steps below.

**Claim B.3.1**.: _Greedy and Balanced Greedy are feasible with probability \(1-e^{-\Omega(c)}\)._

**Proof of Claim B.3.1:** We use **Bernstein's inequality:** Suppose \(x_{1},x_{2},\ldots,x_{n}\) are i.i.d. from a distribution with mean \(\mu\), bounded support \([a,b]\), with variance \(\sigma^{2}\). Then

\[\Pr[|\hat{\mu}-\mu|\geq t]\leq 2\exp\biggl{(}-\frac{n\cdot t^{2}}{2(\sigma^{2}+( b-a)t)}\biggr{)}\text{ where }\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n}x_{i}.\]In Greedy and Balanced Greedy, the output \(\mathbf{x}\) is a \(n_{p}\times n_{r}\) matrix of random variables, where variables from different rows (papers) are independent as different papers are considered individually. These algorithms are feasible if and only if for each reviewer \(r\), \(\sum_{p}x_{p,r}\leq\ell_{r}\). Note that as the similarities are i.i.d. random, the reviewers are symmetric. Using Union Bound across reviewers,

\[\Pr[\mathrm{ALG\ is\ infeasible}]\leq n_{r}\cdot\mathbf{Pr}\left[\sum_{p}x_{p,r _{1}}>\ell_{r}\right],\forall\mathrm{ALG}\in\{\mathrm{Greedy},\mathrm{Balanced \ Greedy}\}.\]

Moreover, the papers are also symmetric. So \(\sum_{p}x_{p,r_{1}}\) is then a sum of \(n_{p}\) i.i.d. random variables. Let their distribution be \(D\). We will bound the probability using Bernstein's inequality. To do this, consider the properties of the distribution \(D\). For both Greedy and Balanced Greedy,

* The expectation \(\mu\) of \(D\) should be \(\ell_{p}/n_{r}\).
* Also, \(D\) is supported on \([0,Q]\subseteq[0,1]\).
* Therefore, \(\sigma^{2}=\mathbf{E}_{x\sim D}[x^{2}]-\mu^{2}\leq\mathbf{E}_{x\sim D}[x^{2}] \leq\mathbf{E}_{x\sim D}[x]=\ell_{p}/n_{r}\).

Also, by assumption (iii), \(2\cdot n_{p}\cdot\ell_{p}\leq n_{r}\cdot\ell_{r}\), we then know \(\ell_{r}/n_{p}\geq 2\cdot\ell_{p}/n_{r}\). So that

\[\mathbf{Pr}\left[\sum_{p}x_{p,r_{1}}>\ell_{r}\right]=\mathbf{Pr}\left[\left| \hat{\mu}-\mu\right|>\frac{\ell_{r}}{n_{p}}-\mu\right]\leq\mathbf{Pr}\left[ \left|\hat{\mu}-\mu\right|\geq\frac{\ell_{r}}{2n_{p}}\right].\]

Letting \(t=\frac{\ell_{r}}{2n_{p}}\), we will use Bernstein's inequality on this formula. According to Bernstein's inequality,

\[\mathbf{Pr}\left[\sum_{p}x_{p,r_{1}}>\ell_{r}\right]\leq 2\exp\!\left(-\frac{n_{p} \cdot(\ell_{r}/2n_{p})^{2}}{2(\ell_{p}/n_{r}+(1-0)(\ell_{r}/2n_{p}))}\right) \leq 2\exp\!\left(-\frac{1}{8}\ell_{r}\right)\!.\]

Then, by assumption (ii), \(\ell_{r}\geq c\cdot\ln(n_{r})\), and we will see \(\forall\mathrm{ALG}\in\{\mathrm{Greedy},\mathrm{Balanced\ Greedy}\}\),

\[\Pr[\mathrm{ALG\ is\ infeasible}]\leq 2n_{r}\cdot e^{-\frac{1}{8}\ell_{r}}=2e^{ \left(1-\frac{1}{8}c\right)\ln(n_{r})}=e^{-\Omega(c)}.\]

This concludes the proof of Claim B.3.1 

For convenience of language, for an assignment \(\mathbf{x}\), define **the total**\(\mathrm{Quality}\)**of paper**\(p\) to be \(\sum_{r}x_{p,r}S_{p,r}\) and **the total**\(\mathrm{PQuality}_{f}\)**of paper**\(p\) to be \(\sum_{r}f(x_{p,r})S_{p,r}\).

Let \(\mathbf{x}^{(b)}=\mathrm{Balanced\ Greedy}(Q),\mathbf{x}^{(g)}=\mathrm{Greedy} (Q)\). For paper \(p\), both Balanced Greedy and Greedy maximize the total \(\mathrm{Quality}\) of \(p\), so \(\mathrm{Quality}(\mathbf{x}^{(b)})=\mathrm{Quality}(\mathbf{x}^{(g)})\). Moreover, this property of the Greedies also gives us the following Claim B.3.2.

**Claim B.3.2**.: _For any feasible assignment \(\mathbf{x}\), \(\mathrm{Quality}(\mathbf{x}^{(b)})\geq\mathrm{Quality}(\mathbf{x})\). The equality holds if and only if for each paper \(p\), \(\mathbf{x}\) maximizes the total \(\mathrm{Quality}\) of \(p\)._

And as PLRA is maximizing \(\mathrm{Quality}\), we further get the following Corollary B.3.1.

**Corollary B.3.1**.: _If \(\mathbf{x}^{(b)}\) and \(\mathbf{x}^{(g)}\) are feasible, then \(\mathbf{x}^{(b)},\mathbf{x}^{(g)}\in\mathrm{PLRA}(Q)\) and \(\forall\mathbf{x}\in\mathrm{PLRA}(Q)\), \(\mathbf{x}\) maximizes the total \(\mathrm{Quality}\) of \(p\)._

Next, we consider the performance of PM.

**Claim B.3.3**.: _For each paper \(p\), \(\mathbf{x}^{(b)}\) uniquely maximizes the total \(\mathrm{PQuality}_{f}\) of \(p\)._

**Proof of Claim B.3.3:** For each paper \(p\), recall that \(\forall i\in\{1,2,\ldots,k\}\), the set of reviewers with similarity \(v_{i}\) to \(p\) is \(R_{p,i}\). By the execution of Balanced Greedy, \(\mathbf{x}^{(b)}\) assigns \(p\) to every reviewer in the \(i\)-th set, \(R_{p,i}\), with the same probability. Let this probability be \(A_{p,i}\). Then, there exists a \(t\in\{1,2,\ldots,k\}\), such that \(A_{p,t+1}=\cdots=A_{p,k}=Q\), \(A_{p,t}<Q\) and \(A_{p,t-1}=\cdots=A_{p,1}=0\).

Suppose that for an assignment \(\mathbf{x}\), there are both a reviewer \(r_{\mathrm{high}}\in R_{p,i}\) such that \(x_{p,r_{\mathrm{high}}}<Q\), and another reviewer \(r_{\mathrm{low}}\in R_{p,j}\) (\(j<i\)) such that \(x_{p,r_{\mathrm{low}}}>0\). Let \(\delta=\min\{Q-x_{p,r_{\mathrm{high}}},x_{p,r_{\mathrm{low}}}\}\). Consider adjusting \(\mathbf{x}\) by decreasing \(x_{p,r_{\mathrm{low}}}\) by \(\delta\) and increasing \(x_{p,r_{\mathrm{high}}}\) by \(\delta\). The total \(\mathrm{PQuality}_{f}\) of \(p\) will first decrease by at most \(\delta f^{\prime}(0)v_{j}\) and then increase by at least \(\delta f^{\prime}(1)v_{i}\). The net increase in the total \(\operatorname{PQuality}_{f}\) of \(p\) will be

\[\geq\delta(f^{\prime}(1)v_{i}-f^{\prime}(0)v_{j})\geq\delta(f^{\prime}(1)v_{i}- f^{\prime}(0)v_{i-1})>0.\]

This shows that the adjustment increases the total \(\operatorname{PQuality}_{f}\) of \(p\), so \(\mathbf{x}\) does not maximize it. Therefore, for an assignment \(\mathbf{x}\) to maximize the total \(\operatorname{PQuality}_{f}\) of \(p\), \(\mathbf{x}\) must assign \(p\) to every reviewer in \(R_{p,t+1},\ldots,R_{p,k}\) with probability \(Q\), and assign \(p\) to every reviewer in \(R_{p,t-1},\ldots,R_{p,1}\) with probability \(0\). It remains to consider the assignment to group \(R_{p,t}\).

Write the total \(\operatorname{PQuality}_{f}\) of \(p\) in \(\mathbf{x}\) as

\[\sum_{i=t+1}^{k}|R_{p,i}|\cdot f(1)v_{i}+\sum_{r\in R_{p,t}}f(x_{p,r})v_{t}\]

For fixed \(p\), the first summation is constant. To maximize the second summation, according the Jensen's inequality, \(x_{p,r},\forall r\in R_{p,t}\) must be the same, which is exactly \(\mathbf{x}^{(b)}\).

This concludes the proof of Claim B.3.3. 

Claim B.3.3 gives us the following Corollary B.3.2.

**Corollary B.3.2**.: _If \(\mathbf{x}^{(b)}\) is feasible, \(\operatorname{PM}(Q,f)=\{\mathbf{x}^{(b)}\}\)._

Now we are ready to proceed to prove Theorem 3. We first prove Theorem 3 (a).

For \(\operatorname{Quality}\), Claim B.3.2 implies that \(\forall\mathbf{x}\in\operatorname{PLRA}(Q)\), \(\operatorname{Quality}(\mathbf{x}^{(b)})\geq\operatorname{Quality}(\mathbf{x})\).

For the randomness metrics, consider each paper \(p\) and again let the set of reviewers with similarity \(v_{i}\) to \(p\) be \(R_{p,i}\). Like in the proof of Claim B.3.3, by the execution of Balanced Greedy, \(\mathbf{x}^{(b)}\) assigns \(p\) to every reviewer in \(R_{p,i}\) with the same probability \(A_{p,i}\), and there exists a \(t\in\{1,2,\ldots,k\}\), such that \(A_{p,t+1}=\cdots=A_{p,k}=Q\), \(A_{p,t}<Q\) and \(A_{p,t-1}=\cdots=A_{p,1}=0\).

By Corollary B.3.1, \(\forall\mathbf{x}\in\operatorname{PLRA}(Q)\), \(\mathbf{x}\) must assign \(p\) to all reviewers in \(R_{p,t+1},\ldots,R_{p,k}\) with probability \(Q\) and assign \(p\) to all reviewers in \(R_{p,1},\ldots,R_{p,t-1}\) with probability \(0\). Among all such assignments, with an argument using Jensen's inequality or simple categorical discussion, we will see that \(\mathbf{x}=\mathbf{x}^{(b)}\) maximizes \(\sum_{r}x_{p,r}\ln(1/x_{p,r}),\sum_{r}\mathbb{I}[x_{p,r}>0]\) and minimizes \(\max_{r}\{x_{p,r}\},\sum_{r}x_{p,r}^{2}\). This shows that Theorem 3 (a) holds.

To show Theorem 3 (b), we will first prove the following Claim B.3.4.

**Claim B.3.4**.: _With probability \(1-e^{-\Omega(c)}\):_

\[\operatorname{Support}(\mathbf{x}^{(b)})>\operatorname{Support}(\mathbf{x}^{( g)}),\operatorname{L2Norm}(\mathbf{x}^{(b)})<\operatorname{L2Norm}(\mathbf{x}^{(g)}), \operatorname{Entropy}(\mathbf{x}^{(b)})>\operatorname{Entropy}(\mathbf{x}^{ (g)}).\]

**Proof of Claim B.3.4:** Recall in Greedy, for each paper \(p\), the sorted reviewer list by decreasing similarity with \(p\) is \(\{r_{1},r_{2},\ldots,r_{n_{r}}\}\). By assumption (iv), \(Q\cdot(n_{r}-1)\geq\ell_{p}\), so \(\lceil\ell_{p}/Q\rceil+1\leq n_{r}\). Suppose for some paper \(p\) and \(i\in\{1,\ldots,k\}\), \(S_{p,r_{\lceil\ell_{p}/Q\rceil}}=S_{p,r_{\lceil\ell_{p}/Q\rceil+1}}=v_{i}\). Then, as by the execution of Greedy, \(x_{p,r_{\lceil\ell_{p}/Q\rceil}}^{(g)}>0\) and \(x_{p,r_{\lceil\ell_{p}/Q\rceil+1}}^{(g)}=0\). Let \(\{r_{\operatorname{left}},\ldots,r_{\operatorname{right}}\}\) be the set of reviewers with similarity \(v_{i}\) to \(p\), where \(\operatorname{left}\leq\lceil\ell_{p}/Q\rceil<\lceil\ell_{p}/Q\rceil+1\leq \operatorname{right}\). Then

\[\mathbf{x}_{p,r_{j}}^{(b)} =\left\{\begin{array}{rl}Q&(j\leq\operatorname{left}-1)\\ \frac{\ell_{p}-Q(\operatorname{left}-1)}{\operatorname{right}-\operatorname{ left}+1}&(\operatorname{left}\leq j\leq\operatorname{right})\\ 0&(j\geq\operatorname{right}+1)\end{array}\right.,\] \[\mathbf{x}_{p,r_{j}}^{(g)} =\left\{\begin{array}{rl}Q&(j\leq\lceil\ell_{p}/Q\rceil-1) \\ \ell_{p}-Q(\lceil\ell_{p}/Q\rceil-1)&(j=\lceil\ell_{p}/Q\rceil)\\ 0&(j\geq\lceil\ell_{p}/Q\rceil+1)\end{array}\right..\]

Note that \(\mathbf{x}_{p,r_{j}}^{(b)}=\mathbf{x}_{p,r_{j}}^{(g)}\) for any \(j\leq\operatorname{left}-1\) and any \(j\geq\operatorname{right}+1\). For \(\operatorname{left}\leq j\leq\operatorname{right}\), \(\mathbf{x}_{p,r_{j}}^{(b)}\) are all equal, but as \(x_{p,r_{\lceil\ell_{p}/Q\rceil+1}}^{(g)}=0\), \(\mathbf{x}_{p,r_{j}}^{(g)}\) are not all equal. So \(\operatorname{Support}(\mathbf{x}^{(b)})>\operatorname{Support}(\mathbf{x}^{(g)})\), and by Jensen's inequality, \(\operatorname{L2Norm}(\mathbf{x}^{(b)})<\operatorname{L2Norm}(\mathbf{x}^{(g)}), \operatorname{Entropy}(\mathbf{x}^{(b)})>\operatorname{Entropy}(\mathbf{x}^{(g)})\).

Therefore, it remains to show that with probability \(1-e^{-\Omega(c)}\), for some paper \(p\), \(S_{p,r_{\lceil t_{p}/Q\rceil}}=S_{p,r_{\lceil t_{p}/Q\rceil+1}}\). For a fixed \(p\), denote the event that \(S_{p,r_{\lceil t_{p}/Q\rceil}}=S_{p,r_{\lceil t_{p}/Q\rceil+1}}\) as \(E_{p}\). Recall that entries in \(\mathbf{S}\) are i.i.d. and uniformly chosen from \(\{v_{1},\ldots,v_{k}\}\). Consider fixing \(S_{p,1},\ldots,S_{p,n_{r}-1}\), and let the \(\lceil\ell_{p}/Q\rceil\)-th largest number in this set be \(\alpha\). Then \(\Pr[S_{p,n_{r}}=\alpha]\geq\frac{1}{k}\). As \(S_{p,n_{r}}=\alpha\) implies \(E_{p}\), \(\Pr[E_{p}=1]\geq\frac{1}{k}\). Therefore, according to assumption (i), \(k\leq\frac{1}{c}\cdot n_{p}\), we know that

\[\Pr[\exists p,E_{p}=1]\geq 1-\left(1-\frac{1}{k}\right)^{n_{p}}\geq 1-\left(1 -\frac{1}{k}\right)^{ck}\geq 1-e^{-c}.\]

This concludes the proof of Claim B.3.4. 

Theorem 3 (b) is implied by Claim B.3.1, Corollary B.3.1, Corollary B.3.2 and Claim B.3.4. 

## Appendix C Discussions

### Directly Optimizing Specific Randomness Metrics with PM

While PM provides one way to introduce randomness into the paper assignment, one natural alternative approach is to simply maximize one specific randomness metric, subject to a constraint on the minimum solution quality. In this section, we show that a slight modification to PM is general enough to capture such approaches.

Specifically, suppose we want to maximize a concave randomness metric \(\mathrm{RM}:[0,1]^{n_{p}\times n_{r}}\rightarrow\mathbb{R}\) over the set of feasible assignments \(S_{\mathrm{feasible}}=\{\mathbf{x}\in[0,1]^{n_{p}\times n_{r}}|\sum_{r}x_{p,r} =\ell_{p},\forall p\text{ and }\sum_{p}x_{p,r}\leq\ell_{r},\forall r\}\) subject to a minimum requirement of the solution quality \(\mathrm{Quality}(\mathbf{x})\geq\tau\cdot\mathrm{Quality}_{\mathrm{OPT}}\), where \(\mathrm{Quality}_{\mathrm{OPT}}=\max_{\mathbf{x}\in S_{\mathrm{feasible}}} \mathrm{Quality}(\mathbf{x})\) and \(\tau\in[0,1]\). The problem can be formulated as

\[\begin{array}{ll}\mathrm{Maximize}&\mathrm{RM}(\mathbf{x})\\ \mathrm{Subject\ to}&\mathrm{Quality}(\mathbf{x})\geq\tau\cdot\mathrm{Quality}_ {\mathrm{OPT}},\\ &\mathbf{x}\in S_{\mathrm{feasible}}.\end{array} \tag{5}\]

We then consider a slight generalization of PM that allows different perturbation functions for each reviewer-paper pair. That is, we change the definition of \(\mathrm{PQuality}_{f}\) (the objective of PM) in Definition 4.2 to

\[\mathrm{PQuality}_{f}(\mathbf{x})=\sum_{p}\sum_{r}S_{p,r}\cdot f_{p,r}(x_{p,r }).\]

Then we have the following result:

**Theorem 4**.: _If \(f_{p,r}(x)\) is (i) \(x+\frac{\lambda}{S_{p,r}}\mathbb{I}[x>0]\), (ii) \(x-\frac{\lambda}{S_{p,r}}x\ln(x)\), or (iii) \(x-\frac{\lambda}{S_{p,r}}x^{2}\), then PM achieves the optimal trade-offs between \(\mathrm{Quality}(\mathbf{x})\) and (i) \(\mathrm{Support}(\mathbf{x})\), (ii) \(\mathrm{Entropy}(\mathbf{x})\), or (iii) \(\mathrm{L2Norm}^{2}(\mathbf{x})\) respectively with different values of \(\lambda\in[0,+\infty)\)._

In fact, the proof of Theorem 4 also shows that PM-Q can be viewed as a algorithm that achieves the optimal trade-off between \(\mathrm{Quality}(\mathbf{x})\) and another randomness metric \((\sum_{p,r}S_{p,r}x_{p,r}^{2})\), a similarity-weighted version of squared L2 norm of \(\mathbf{x}\). Next, we will proceed to prove Theorem 4.

**Proof of Theorem 4:** When \(\tau\in[0,1]\), the maximization problem (5) always has at least one feasible solution. Let the optimal value of (5) be \(\mathrm{RM}^{*}(\tau)\). \(\mathrm{RM}^{*}(\tau)\) describes the optimal trade-off between \(\mathrm{Quality}(\mathbf{x})\) and \(\mathrm{RM}(\mathbf{x})\). We can show the following property of \(\mathrm{RM}^{*}(\tau)\).

**Lemma C.1**.: \(\mathrm{RM}^{*}(\tau)\) _is a concave and non-increasing function of \(\tau\in[0,1]\)._

**Proof of Lemma C.1:** Let \(\mathbf{x}_{1}\) be the optimal solution of (5) when \(\tau=\tau_{1}\) and \(\mathbf{x}_{2}\) be the optimal solution of (5) when \(\tau=\tau_{2}\) where \(0\leq\tau_{1}<\tau_{2}\leq 1\). Then, we have \(\mathrm{Quality}(\mathbf{x}_{2})\geq\tau_{2}\cdot\mathrm{Quality}_{\mathrm{ OPT}}>\tau_{1}\cdot\mathrm{Quality}_{\mathrm{OPT}}\) and \(\mathbf{x}_{2}\) is a feasible solution of of (5) when \(\tau=\tau_{1}\). Therefore, \(\mathrm{RM}(\mathbf{x}_{1})\geq\mathrm{RM}(\mathbf{x}_{2})\), i.e., \(\mathrm{RM}^{*}(\tau_{1})\geq\mathrm{RM}^{*}(\tau_{2})\). This shows that \(\mathrm{RM}^{*}(\tau)\) is a non-increasing function of \(\tau\).

Moreover, let \(\mathbf{x}_{m}=\frac{1}{2}(\mathbf{x}_{1}+\mathbf{x}_{2})\). Then, \(\mathrm{Quality}(\mathbf{x}_{m})\geq\frac{1}{2}(\tau_{1}+\tau_{2})\cdot \mathrm{Quality}_{\mathrm{OPT}}\) and \(\mathbf{x}_{m}\in S_{\mathrm{feasible}}\). Thus \(\mathbf{x}_{m}\) is a feasible solution of of (5) when \(\tau=\frac{1}{2}(\tau_{1}+\tau_{2})\). Since \(\mathrm{RM}\) is a concave function,\(\mathrm{RM}^{*}(\frac{1}{2}(\tau_{1}+\tau_{2}))\geq\mathrm{RM}(\mathbf{x}_{m})\geq \frac{1}{2}(\mathrm{RM}(\mathbf{x}_{1})+\mathrm{RM}(\mathbf{x}_{2}))=\frac{1}{2 }(\mathrm{RM}^{*}(\tau_{1})+\mathrm{RM}^{*}(\tau_{2}))\). This shows that \(\mathrm{RM}^{*}(\tau)\) is a concave function of \(\tau\). 

Now, for \(\lambda\geq 0\), consider another optimization program as follows:

\[\begin{array}{ll}\text{Maximize}&\mathrm{Quality}(\mathbf{x})+\lambda\cdot \mathrm{RM}(\mathbf{x})\\ \text{Subject to}&\mathbf{x}\in S_{\text{feasible}}.\end{array} \tag{6}\]

Let the solution of (6) be \(x_{\lambda}^{*}\). Lemma C.1 gives us the following corollary.

**Corollary C.1.1**.: \[\{(\tau,\mathrm{RM}^{*}(\tau))\mid\tau\in(0,1]\}=\{(\mathrm{Quality}(\mathbf{x }_{\lambda}^{*})/\mathrm{Quality}_{\mathrm{OPT}},\mathrm{RM}(\mathbf{x}_{ \lambda}^{*}))\mid\lambda\in[0,+\infty)\}.\]

Plugging in different randomness metrics \(\mathrm{RM}(\mathbf{x})\) concludes the proof of Theorem 4. 

### Incorporating Various Constraints in PM

In some of the currently-deployed conference review systems, there are various additional constraints on the assignment of papers to reviewers. We will discuss in this section how to incorporate some of these constraints in PM. Specifically, we consider the following constraints from [20]:

1. **Seniority:** Each paper is assigned to \(\geq 1\) senior reviewer.
2. **Geographic diversity:** No \(2\) reviewers assigned to the same paper belong to the same region.

**Seniority.** Let the set of senior reviewers be \(S_{\text{senior}}\). We can incorporate the seniority constraint in PM by modifying PM to the following optimization program.

\[\begin{array}{ll}\text{Maximize}&\mathrm{PQuality}_{f}(\mathbf{x})\\ \text{Subject to}&\sum_{r}x_{p,r}=\ell_{p}&\forall p\in\mathcal{P},\\ &\sum_{r\in S_{\text{senior}}}x_{p,r}\geq 1&\forall p\in\mathcal{P},\\ &\sum_{p}x_{p,r}\leq\ell_{r}&\forall r\in\mathcal{R},\\ &0\leq x_{p,r}\leq Q&\forall p\in\mathcal{P},r\in\mathcal{R}.\end{array}\]

With a slightly different sampling algorithm, we can show that the obtained randomized assignment can be realized by a distribution of deterministic assignments that satisfies the seniority constraint [22].

**Geographic diversity.** Let the set of regions be \(S_{\text{region}}\). We can incorporate the geographic diversity constraint in PM by modifying PM to the following optimization program.

\[\begin{array}{ll}\text{Maximize}&\mathrm{PQuality}_{f}(\mathbf{x})\\ \text{Subject to}&\sum_{r}x_{p,r}=\ell_{p}&\forall p\in\mathcal{P},\\ &\sum_{r\text{ belongs to }g}x_{p,r}\leq 1&\forall p\in\mathcal{P},g\in S_{ \text{region}},\\ &\sum_{p}x_{p,r}\leq\ell_{r}&\forall r\in\mathcal{R},\\ &0\leq x_{p,r}\leq Q&\forall p\in\mathcal{P},r\in\mathcal{R}.\end{array}\]

The obtained assignment can also be realized by a distribution of deterministic assignments that satisfies the geographic diversity constraint with a slightly different sampling algorithm [22].

Apart from the constraints mentioned above, there are also some other common constraints that cannot be easily incorporated in PM [20]. We leave incorporating them for future work.